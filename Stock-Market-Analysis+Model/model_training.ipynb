{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardobenjamin/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from SimulateDay import stock_market_simulation, scale_data,train_Optimal_Action, _select_stock, get_stock_data, add_columns, train_Optimal_Action\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def importModels(symbol):\n",
    "    specificModel = joblib.load(f\"models/{symbol}_model.pkl\")\n",
    "    noCovidModel = train_Optimal_Action(symbol=symbol, action_column='Action')\n",
    "    generalModel = xgb.Booster()    \n",
    "    generalModel.load_model('models/all_stocks_incremental_model.pkl') \n",
    "    return specificModel, generalModel, noCovidModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for TSLA ...\n",
      "Adding columns for TSLA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:238: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  '10_Day_Return', '20_Day_Return', '50_Day_Return', '200_Day_Return']].idxmax(axis=1)\n",
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:238: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  '10_Day_Return', '20_Day_Return', '50_Day_Return', '200_Day_Return']].idxmax(axis=1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m specificModel, generalModel, noCovidModel \u001b[38;5;241m=\u001b[39m importModels(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTSLA\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m, in \u001b[0;36mimportModels\u001b[0;34m(symbol)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimportModels\u001b[39m(symbol):\n\u001b[1;32m     15\u001b[0m     specificModel \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m     noCovidModel \u001b[38;5;241m=\u001b[39m train_Optimal_Action(symbol\u001b[38;5;241m=\u001b[39msymbol, action_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAction\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m     generalModel \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mBooster()    \n\u001b[1;32m     18\u001b[0m     generalModel\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/all_stocks_incremental_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "File \u001b[0;32m~/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:546\u001b[0m, in \u001b[0;36mtrain_Optimal_Action\u001b[0;34m(symbol, action_column)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdding columns for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    545\u001b[0m stock_df \u001b[38;5;241m=\u001b[39m add_columns(stock_df)\n\u001b[0;32m--> 546\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m scale_data(stock_df)\n\u001b[1;32m    547\u001b[0m X \u001b[38;5;241m=\u001b[39m preprocessed[features]\n\u001b[1;32m    548\u001b[0m y \u001b[38;5;241m=\u001b[39m stock_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAction\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:453\u001b[0m, in \u001b[0;36mscale_data\u001b[0;34m(stock_df)\u001b[0m\n\u001b[1;32m    451\u001b[0m min_max_scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m    452\u001b[0m stock_df \u001b[38;5;241m=\u001b[39m add_columns(stock_df)\n\u001b[0;32m--> 453\u001b[0m stock_df[features] \u001b[38;5;241m=\u001b[39m min_max_scaler\u001b[38;5;241m.\u001b[39mfit_transform(stock_df[features])\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stock_df[features]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1084\u001b[0m             (\n\u001b[1;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1094\u001b[0m         )\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:450\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_fit(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:490\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    487\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m    489\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 490\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    491\u001b[0m     X,\n\u001b[1;32m    492\u001b[0m     reset\u001b[38;5;241m=\u001b[39mfirst_pass,\n\u001b[1;32m    493\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_array_api\u001b[38;5;241m.\u001b[39msupported_float_dtypes(xp),\n\u001b[1;32m    494\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    495\u001b[0m )\n\u001b[1;32m    497\u001b[0m data_min \u001b[38;5;241m=\u001b[39m _array_api\u001b[38;5;241m.\u001b[39m_nanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    498\u001b[0m data_max \u001b[38;5;241m=\u001b[39m _array_api\u001b[38;5;241m.\u001b[39m_nanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1064\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1065\u001b[0m         array,\n\u001b[1;32m   1066\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1067\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1068\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1069\u001b[0m     )\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    124\u001b[0m     X,\n\u001b[1;32m    125\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[1;32m    126\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[1;32m    127\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[1;32m    128\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    129\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    130\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     )\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "\n",
    "specificModel, generalModel, noCovidModel = importModels('TSLA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Volume', 'MA_10', 'MA_20', 'MA_50', 'MA_200', 'std_10',\n",
    "                'std_20', 'std_50', 'std_200', 'upper_band_10', 'lower_band_10',\n",
    "                'upper_band_20', 'lower_band_20', 'upper_band_50', 'lower_band_50',\n",
    "                'upper_band_200', 'lower_band_200', 'Golden_Cross_Short', 'Golden_Cross_Medium',\n",
    "                'Golden_Cross_Long', 'Death_Cross_Short', 'Death_Cross_Medium', 'Death_Cross_Long',\n",
    "                'ROC', 'AVG_Volume_10', 'AVG_Volume_20', 'AVG_Volume_50', 'AVG_Volume_200', 'Doji',\n",
    "                'Bullish_Engulfing', 'Bearish_Engulfing', 'MACD', 'Signal', 'MACD_Hist', 'TR', 'ATR',\n",
    "                'RSI_10_Day', '10_Day_ROC', 'Resistance_10_Day', 'Support_10_Day', 'Resistance_20_Day',\n",
    "                'Support_20_Day', 'Resistance_50_Day', 'Support_50_Day', 'Volume_MA_10', 'Volume_MA_20',\n",
    "                'Volume_MA_50', 'OBV', 'Z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classification_models_basic(X_train, y_train, X_test, y_test):\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"SVM\": SVC(random_state=42),\n",
    "        \"XGBoost\": xgb.XGBClassifier(n_estimators=100, random_state=42),\n",
    "        \"Stacking\": StackingClassifier(\n",
    "            estimators=[\n",
    "                ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "                ('xgb', xgb.XGBClassifier(n_estimators=100, random_state=42)),\n",
    "            ],\n",
    "            final_estimator=xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        results[name] = {\n",
    "            \"Model\": model,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Classification Report\": report\n",
    "        }\n",
    "        \n",
    "        print(f\"--- {name} Results ---\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return results\n",
    "def train_classification_model_tuned(X_train, y_train, X_test, y_test):\n",
    "    models = {\n",
    "        \"Logistic Regression Tuned\": LogisticRegression(C=1.0, penalty='l2', solver='saga', max_iter=1000, random_state=42),\n",
    "        \"Random Forest Tuned\": RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=10, min_samples_leaf=5, max_features='sqrt', random_state=42),\n",
    "        \"SVM Tuned \": SVC(random_state=42, C=10.0, kernel='rbf',gamma='scale'),\n",
    "        \"XGBoost Tuned\": xgb.XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=6, subsample=0.8, colsample_bytree=0.8, gamma=0.1, random_state=42),\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        results[name] = {\n",
    "            \"Model\": model,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Classification Report\": report\n",
    "        }\n",
    "        \n",
    "        print(f\"--- {name} Results ---\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulations_on_models(X_train, y_train, X_test, y_test, stock_data, initial_cash, days):\n",
    "    # Train different models\n",
    "    trained_models = train_classification_models_basic(X_train, y_train, X_test, y_test)\n",
    "    # trained_models_tuned = train_classification_models_basic(X_train, y_train, X_test, y_test)\n",
    "    # trained_models = {**trained_models_basic, **trained_models_tuned}    \n",
    "    # # Dictionary to store simulation results for each model\n",
    "    simulation_results = {}\n",
    "    \n",
    "    # Run stock market simulation for each trained model\n",
    "    for model_name, model_data in trained_models.items():\n",
    "        model = model_data['Model']\n",
    "        print(f\"Running stock market simulation for {model_name}...\")\n",
    "        \n",
    "        # Run the simulation\n",
    "        simulation_df, final_cash = stock_market_simulation(model, initial_cash, days, stock_data)\n",
    "        \n",
    "        # Store the simulation results\n",
    "        simulation_results[model_name] = simulation_df\n",
    "        \n",
    "    return simulation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:238: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  '10_Day_Return', '20_Day_Return', '50_Day_Return', '200_Day_Return']].idxmax(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# stock_df = get_stock_data('TSLA')\n",
    "# print(f'Adding columns...')\n",
    "stock_df = pd.read_csv('data/sp500_stocks.csv')\n",
    "stock_df = stock_df[stock_df['Symbol'] == 'TSLA']\n",
    "print(f'Scaling data...')\n",
    "preprocessed = scale_data(stock_df)\n",
    "X = preprocessed[features]\n",
    "y = stock_df['Action']\n",
    "# y = y.map({'Buy': 0, 'Sell': 1, 'Hold': 2})\n",
    "X_train, _, y_train, _ = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardobenjamin/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression Results ---\n",
      "Accuracy: 0.8644922663080027\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      1045\n",
      "           1       0.84      0.84      0.84       797\n",
      "           2       0.90      0.87      0.89      1132\n",
      "\n",
      "    accuracy                           0.86      2974\n",
      "   macro avg       0.86      0.86      0.86      2974\n",
      "weighted avg       0.87      0.86      0.86      2974\n",
      "\n",
      "Training Random Forest...\n",
      "--- Random Forest Results ---\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1045\n",
      "           1       1.00      1.00      1.00       797\n",
      "           2       1.00      1.00      1.00      1132\n",
      "\n",
      "    accuracy                           1.00      2974\n",
      "   macro avg       1.00      1.00      1.00      2974\n",
      "weighted avg       1.00      1.00      1.00      2974\n",
      "\n",
      "Training SVM...\n",
      "--- SVM Results ---\n",
      "Accuracy: 0.8375924680564896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84      1045\n",
      "           1       0.80      0.87      0.83       797\n",
      "           2       0.94      0.76      0.84      1132\n",
      "\n",
      "    accuracy                           0.84      2974\n",
      "   macro avg       0.84      0.84      0.84      2974\n",
      "weighted avg       0.85      0.84      0.84      2974\n",
      "\n",
      "Training XGBoost...\n",
      "--- XGBoost Results ---\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1045\n",
      "           1       1.00      1.00      1.00       797\n",
      "           2       1.00      1.00      1.00      1132\n",
      "\n",
      "    accuracy                           1.00      2974\n",
      "   macro avg       1.00      1.00      1.00      2974\n",
      "weighted avg       1.00      1.00      1.00      2974\n",
      "\n",
      "Training Stacking...\n",
      "--- Stacking Results ---\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1045\n",
      "           1       1.00      1.00      1.00       797\n",
      "           2       1.00      1.00      1.00      1132\n",
      "\n",
      "    accuracy                           1.00      2974\n",
      "   macro avg       1.00      1.00      1.00      2974\n",
      "weighted avg       1.00      1.00      1.00      2974\n",
      "\n",
      "Running stock market simulation for Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:238: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  '10_Day_Return', '20_Day_Return', '50_Day_Return', '200_Day_Return']].idxmax(axis=1)\n",
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  modelDecisionDf = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running stock market simulation for Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:238: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  '10_Day_Return', '20_Day_Return', '50_Day_Return', '200_Day_Return']].idxmax(axis=1)\n",
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  modelDecisionDf = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running stock market simulation for SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:238: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  '10_Day_Return', '20_Day_Return', '50_Day_Return', '200_Day_Return']].idxmax(axis=1)\n",
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  modelDecisionDf = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running stock market simulation for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:238: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  '10_Day_Return', '20_Day_Return', '50_Day_Return', '200_Day_Return']].idxmax(axis=1)\n",
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  modelDecisionDf = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running stock market simulation for Stacking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:238: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  '10_Day_Return', '20_Day_Return', '50_Day_Return', '200_Day_Return']].idxmax(axis=1)\n",
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  modelDecisionDf = pd.concat(\n"
     ]
    }
   ],
   "source": [
    "simResults = run_simulations_on_models(X_train, y_train, X_train, y_train,get_stock_data('TSLA').tail(365) , 10000, 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:238: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  '10_Day_Return', '20_Day_Return', '50_Day_Return', '200_Day_Return']].idxmax(axis=1)\n",
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  modelDecisionDf = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 30: Bought 1 share at 256.7900085449219, Cash left: 9743.209991455078\n",
      "Day 34: Sold 1 share at 259.4599914550781, Cash: 10002.669982910156\n",
      "Day 83: Bought 1 share at 256.8999938964844, Cash left: 9745.769989013672\n",
      "Day 84: Sold 1 share at 258.0799865722656, Cash: 10003.849975585938\n",
      "Day 85: Bought 1 share at 245.0099945068359, Cash left: 9758.839981079102\n",
      "Day 87: Bought 1 share at 251.9199981689453, Cash left: 9506.919982910156\n",
      "Day 88: Sold 1 share at 251.4900054931641, Cash: 9758.40998840332\n",
      "Day 89: Sold 1 share at 248.5, Cash: 10006.90998840332\n",
      "Day 91: Bought 1 share at 267.4800109863281, Cash left: 9739.429977416992\n",
      "Day 94: Sold 1 share at 274.3900146484375, Cash: 10013.81999206543\n",
      "Day 111: Bought 1 share at 263.6199951171875, Cash left: 9750.199996948242\n",
      "Day 112: Bought 1 share at 262.989990234375, Cash left: 9487.210006713867\n",
      "Day 113: Bought 1 share at 258.8699951171875, Cash left: 9228.34001159668\n",
      "Day 114: Sold 1 share at 251.1199951171875, Cash: 9479.460006713867\n",
      "Day 115: Sold 1 share at 253.9199981689453, Cash: 9733.380004882812\n",
      "Day 116: Sold 1 share at 254.8500061035156, Cash: 9988.230010986328\n",
      "Day 131: Bought 1 share at 222.17999267578125, Cash left: 9766.050018310547\n",
      "Day 132: Bought 1 share at 222.11000061035156, Cash left: 9543.940017700195\n",
      "Day 133: Bought 1 share at 209.97999572753903, Cash left: 9333.960021972656\n",
      "Day 134: Bought 1 share at 214.6499938964844, Cash left: 9119.310028076172\n",
      "Day 138: Bought 1 share at 233.58999633789065, Cash left: 8885.720031738281\n",
      "Day 139: Bought 1 share at 234.3000030517578, Cash left: 8651.420028686523\n",
      "Day 140: Bought 1 share at 235.6000061035156, Cash left: 8415.820022583008\n",
      "Day 141: Bought 1 share at 241.1999969482422, Cash left: 8174.620025634766\n",
      "Day 142: Bought 1 share at 234.2100067138672, Cash left: 7940.410018920898\n",
      "Day 143: Bought 1 share at 235.4499969482422, Cash left: 7704.960021972656\n",
      "Day 144: Bought 1 share at 236.0800018310547, Cash left: 7468.880020141602\n",
      "Day 146: Bought 1 share at 244.13999938964844, Cash left: 7224.740020751953\n",
      "Day 147: Bought 1 share at 240.0800018310547, Cash left: 6984.660018920898\n",
      "Day 148: Bought 1 share at 238.8300018310547, Cash left: 6745.830017089844\n",
      "Day 149: Bought 1 share at 235.5800018310547, Cash left: 6510.250015258789\n",
      "Day 150: Sold 1 share at 238.72000122070312, Cash: 6748.970016479492\n",
      "Day 151: Sold 1 share at 239.3699951171875, Cash: 6988.34001159668\n",
      "Day 152: Sold 1 share at 242.63999938964844, Cash: 7230.980010986328\n",
      "Day 153: Sold 1 share at 243.83999633789065, Cash: 7474.820007324219\n",
      "Day 154: Sold 1 share at 239.7400054931641, Cash: 7714.560012817383\n",
      "Day 155: Sold 1 share at 237.0099945068359, Cash: 7951.570007324219\n",
      "Day 156: Sold 1 share at 239.2899932861328, Cash: 8190.860000610352\n",
      "Day 157: Sold 1 share at 251.0500030517578, Cash: 8441.91000366211\n",
      "Day 158: Bought 1 share at 253.5, Cash left: 8188.410003662109\n",
      "Day 159: Bought 1 share at 252.0800018310547, Cash left: 7936.330001831055\n",
      "Day 161: Sold 1 share at 247.13999938964844, Cash: 8183.470001220703\n",
      "Day 162: Sold 1 share at 254.5, Cash: 8437.970001220703\n",
      "Day 163: Sold 1 share at 252.5399932861328, Cash: 8690.509994506836\n",
      "Day 164: Bought 1 share at 256.6099853515625, Cash left: 8433.900009155273\n",
      "Day 166: Sold 1 share at 253.17999267578125, Cash: 8687.080001831055\n",
      "Day 167: Sold 1 share at 248.47999572753903, Cash: 8935.559997558594\n",
      "Day 168: Sold 1 share at 248.4199981689453, Cash: 9183.979995727539\n",
      "Day 169: Sold 1 share at 238.4499969482422, Cash: 9422.429992675781\n",
      "Day 170: Sold 1 share at 237.92999267578125, Cash: 9660.359985351562\n",
      "Day 171: Sold 1 share at 237.4900054931641, Cash: 9897.849990844727\n",
      "Day 172: Sold 1 share at 240.4499969482422, Cash: 10138.299987792969\n",
      "Day 195: Bought 1 share at 193.57000732421875, Cash left: 9944.72998046875\n",
      "Day 196: Bought 1 share at 188.1300048828125, Cash left: 9756.599975585938\n",
      "Day 197: Bought 1 share at 184.02000427246097, Cash left: 9572.579971313477\n",
      "Day 198: Bought 1 share at 188.7100067138672, Cash left: 9383.86996459961\n",
      "Day 200: Bought 1 share at 199.9499969482422, Cash left: 9183.919967651367\n",
      "Day 201: Bought 1 share at 193.7599945068359, Cash left: 8990.159973144531\n",
      "Day 202: Bought 1 share at 194.77000427246097, Cash left: 8795.38996887207\n",
      "Day 203: Bought 1 share at 197.41000366210935, Cash left: 8597.979965209961\n",
      "Day 204: Bought 1 share at 191.97000122070312, Cash left: 8406.009963989258\n",
      "Day 205: Bought 1 share at 199.3999938964844, Cash left: 8206.609970092773\n",
      "Day 206: Bought 1 share at 199.72999572753903, Cash left: 8006.879974365234\n",
      "Day 207: Bought 1 share at 202.0399932861328, Cash left: 7804.839981079102\n",
      "Day 208: Bought 1 share at 201.8800048828125, Cash left: 7602.959976196289\n",
      "Day 209: Bought 1 share at 202.63999938964844, Cash left: 7400.319976806641\n",
      "Day 210: Bought 1 share at 188.13999938964844, Cash left: 7212.179977416992\n",
      "Day 211: Bought 1 share at 180.7400054931641, Cash left: 7031.439971923828\n",
      "Day 212: Sold 1 share at 176.5399932861328, Cash: 7207.979965209961\n",
      "Day 214: Sold 1 share at 175.33999633789062, Cash: 7383.319961547852\n",
      "Day 216: Sold 1 share at 177.5399932861328, Cash: 7560.859954833984\n",
      "Day 217: Sold 1 share at 169.47999572753906, Cash: 7730.339950561523\n",
      "Day 218: Sold 1 share at 162.5, Cash: 7892.839950561523\n",
      "Day 219: Sold 1 share at 163.57000732421875, Cash: 8056.409957885742\n",
      "Day 221: Sold 1 share at 171.32000732421875, Cash: 8227.729965209961\n",
      "Day 222: Sold 1 share at 175.66000366210938, Cash: 8403.38996887207\n",
      "Day 223: Bought 1 share at 172.82000732421875, Cash left: 8230.569961547852\n",
      "Day 224: Sold 1 share at 170.8300018310547, Cash: 8401.399963378906\n",
      "Day 225: Sold 1 share at 172.6300048828125, Cash: 8574.029968261719\n",
      "Day 227: Bought 1 share at 179.8300018310547, Cash left: 8394.199966430664\n",
      "Day 228: Bought 1 share at 175.7899932861328, Cash left: 8218.409973144531\n",
      "Day 229: Bought 1 share at 175.22000122070312, Cash left: 8043.189971923828\n",
      "Day 230: Bought 1 share at 166.6300048828125, Cash left: 7876.559967041016\n",
      "Day 231: Sold 1 share at 168.3800048828125, Cash: 8044.939971923828\n",
      "Day 232: Sold 1 share at 171.11000061035156, Cash: 8216.04997253418\n",
      "Day 233: Bought 1 share at 164.89999389648438, Cash left: 8051.149978637695\n",
      "Day 235: Sold 1 share at 176.8800048828125, Cash: 8228.029983520508\n",
      "Day 236: Bought 1 share at 171.75999450683594, Cash left: 8056.269989013672\n",
      "Day 237: Sold 1 share at 174.60000610351562, Cash: 8230.869995117188\n",
      "Day 238: Bought 1 share at 171.0500030517578, Cash left: 8059.81999206543\n",
      "Day 239: Sold 1 share at 161.47999572753906, Cash: 8221.299987792969\n",
      "Day 240: Sold 1 share at 157.11000061035156, Cash: 8378.40998840332\n",
      "Day 241: Sold 1 share at 155.4499969482422, Cash: 8533.859985351562\n",
      "Day 242: Sold 1 share at 149.92999267578125, Cash: 8683.789978027344\n",
      "Day 243: Sold 1 share at 147.0500030517578, Cash: 8830.839981079102\n",
      "Day 244: Sold 1 share at 142.0500030517578, Cash: 8972.88998413086\n",
      "Day 245: Sold 1 share at 144.67999267578125, Cash: 9117.56997680664\n",
      "Day 248: Bought 1 share at 168.2899932861328, Cash left: 8949.279983520508\n",
      "Day 250: Bought 1 share at 183.27999877929688, Cash left: 8765.999984741211\n",
      "Day 251: Bought 1 share at 179.99000549316406, Cash left: 8586.009979248047\n",
      "Day 252: Bought 1 share at 180.00999450683594, Cash left: 8405.999984741211\n",
      "Day 253: Bought 1 share at 181.19000244140625, Cash left: 8224.809982299805\n",
      "Day 254: Bought 1 share at 184.7599945068359, Cash left: 8040.049987792969\n",
      "Day 255: Bought 1 share at 177.80999755859375, Cash left: 7862.239990234375\n",
      "Day 256: Bought 1 share at 174.72000122070312, Cash left: 7687.519989013672\n",
      "Day 257: Bought 1 share at 171.97000122070312, Cash left: 7515.549987792969\n",
      "Day 258: Bought 1 share at 168.47000122070312, Cash left: 7347.079986572266\n",
      "Day 260: Sold 1 share at 177.5500030517578, Cash: 7524.629989624023\n",
      "Day 261: Bought 1 share at 173.99000549316406, Cash left: 7350.639984130859\n",
      "Day 263: Sold 1 share at 177.4600067138672, Cash: 7528.099990844727\n",
      "Day 264: Sold 1 share at 174.9499969482422, Cash: 7703.049987792969\n",
      "Day 266: Bought 1 share at 180.11000061035156, Cash left: 7522.939987182617\n",
      "Day 267: Sold 1 share at 173.74000549316406, Cash: 7696.679992675781\n",
      "Day 269: Bought 1 share at 176.75, Cash left: 7519.929992675781\n",
      "Day 270: Sold 1 share at 176.19000244140625, Cash: 7696.1199951171875\n",
      "Day 271: Sold 1 share at 178.7899932861328, Cash: 7874.90998840332\n",
      "Day 272: Sold 1 share at 178.0800018310547, Cash: 8052.989990234375\n",
      "Day 273: Sold 1 share at 176.2899932861328, Cash: 8229.279983520508\n",
      "Day 274: Bought 1 share at 174.77000427246094, Cash left: 8054.509979248047\n",
      "Day 275: Sold 1 share at 175.0, Cash: 8229.509979248047\n",
      "Day 276: Sold 1 share at 177.94000244140625, Cash: 8407.449981689453\n",
      "Day 277: Sold 1 share at 177.47999572753906, Cash: 8584.929977416992\n",
      "Day 278: Sold 1 share at 173.7899932861328, Cash: 8758.719970703125\n",
      "Day 279: Sold 1 share at 170.66000366210938, Cash: 8929.379974365234\n",
      "Day 280: Sold 1 share at 177.2899932861328, Cash: 9106.669967651367\n",
      "Day 281: Sold 1 share at 182.47000122070312, Cash: 9289.13996887207\n",
      "Day 282: Sold 1 share at 178.00999450683594, Cash: 9467.149963378906\n",
      "Day 283: Sold 1 share at 187.44000244140625, Cash: 9654.589965820312\n",
      "Day 284: Bought 1 share at 184.86000061035156, Cash left: 9469.729965209961\n",
      "Day 285: Sold 1 share at 181.57000732421875, Cash: 9651.29997253418\n",
      "Day 286: Bought 1 share at 183.0099945068359, Cash left: 9468.289978027344\n",
      "Day 287: Sold 1 share at 182.5800018310547, Cash: 9650.869979858398\n",
      "Day 289: Bought 1 share at 196.3699951171875, Cash left: 9454.499984741211\n",
      "Day 290: Bought 1 share at 197.4199981689453, Cash left: 9257.079986572266\n",
      "Day 291: Bought 1 share at 197.8800048828125, Cash left: 9059.199981689453\n",
      "Day 292: Bought 1 share at 209.86000061035156, Cash left: 8849.339981079102\n",
      "Day 293: Bought 1 share at 231.2599945068359, Cash left: 8618.079986572266\n",
      "Day 294: Bought 1 share at 246.38999938964844, Cash left: 8371.689987182617\n",
      "Day 295: Bought 1 share at 251.52000427246097, Cash left: 8120.169982910156\n",
      "Day 296: Bought 1 share at 252.94000244140625, Cash left: 7867.22998046875\n",
      "Day 297: Bought 1 share at 262.3299865722656, Cash left: 7604.899993896484\n",
      "Day 298: Bought 1 share at 263.260009765625, Cash left: 7341.639984130859\n",
      "Day 299: Bought 1 share at 241.02999877929688, Cash left: 7100.6099853515625\n",
      "Day 301: Bought 1 share at 252.63999938964844, Cash left: 6847.969985961914\n",
      "Day 302: Bought 1 share at 256.55999755859375, Cash left: 6591.40998840332\n",
      "Day 303: Bought 1 share at 248.5, Cash left: 6342.90998840332\n",
      "Day 304: Bought 1 share at 249.22999572753903, Cash left: 6093.679992675781\n",
      "Day 305: Bought 1 share at 239.1999969482422, Cash left: 5854.479995727539\n",
      "Day 307: Sold 1 share at 246.3800048828125, Cash: 6100.860000610352\n",
      "Day 308: Sold 1 share at 215.9900054931641, Cash: 6316.850006103516\n",
      "Day 310: Sold 1 share at 219.8000030517578, Cash: 6536.650009155273\n",
      "Day 312: Sold 1 share at 222.6199951171875, Cash: 6759.270004272461\n",
      "Day 314: Sold 1 share at 216.86000061035156, Cash: 6976.1300048828125\n",
      "Day 315: Sold 1 share at 207.6699981689453, Cash: 7183.800003051758\n",
      "Day 316: Sold 1 share at 198.8800048828125, Cash: 7382.68000793457\n",
      "Day 317: Sold 1 share at 200.63999938964844, Cash: 7583.320007324219\n",
      "Day 318: Sold 1 share at 191.7599945068359, Cash: 7775.080001831055\n",
      "Day 320: Sold 1 share at 200.0, Cash: 7975.080001831055\n",
      "Day 321: Sold 1 share at 197.4900054931641, Cash: 8172.570007324219\n",
      "Day 323: Sold 1 share at 201.3800048828125, Cash: 8373.950012207031\n",
      "Day 325: Sold 1 share at 216.1199951171875, Cash: 8590.070007324219\n",
      "Day 327: Bought 1 share at 221.1000061035156, Cash left: 8368.970001220703\n",
      "Day 328: Bought 1 share at 223.27000427246097, Cash left: 8145.699996948242\n",
      "Day 329: Bought 1 share at 210.66000366210935, Cash left: 7935.039993286133\n",
      "Day 331: Bought 1 share at 213.2100067138672, Cash left: 7721.829986572266\n",
      "Day 332: Sold 1 share at 209.2100067138672, Cash: 7931.039993286133\n",
      "Day 333: Sold 1 share at 205.75, Cash: 8136.789993286133\n",
      "Day 334: Sold 1 share at 206.27999877929688, Cash: 8343.06999206543\n",
      "Day 336: Sold 1 share at 210.6000061035156, Cash: 8553.669998168945\n",
      "Day 339: Bought 1 share at 210.72999572753903, Cash left: 8342.940002441406\n",
      "Day 340: Sold 1 share at 216.27000427246097, Cash: 8559.210006713867\n",
      "Day 342: Sold 1 share at 228.1300048828125, Cash: 8787.34001159668\n",
      "Day 343: Bought 1 share at 229.80999755859375, Cash left: 8557.530014038086\n",
      "Day 344: Bought 1 share at 230.2899932861328, Cash left: 8327.240020751953\n",
      "Day 345: Bought 1 share at 226.77999877929688, Cash left: 8100.460021972656\n",
      "Day 347: Bought 1 share at 227.1999969482422, Cash left: 7873.260025024414\n",
      "Day 349: Bought 1 share at 238.25, Cash left: 7635.010025024414\n",
      "Day 350: Bought 1 share at 250.0, Cash left: 7385.010025024414\n",
      "Day 351: Bought 1 share at 254.27000427246097, Cash left: 7130.740020751953\n",
      "Day 352: Bought 1 share at 257.0199890136719, Cash left: 6873.720031738281\n",
      "Day 353: Bought 1 share at 254.22000122070312, Cash left: 6619.500030517578\n",
      "Day 355: Bought 1 share at 261.6300048828125, Cash left: 6357.870025634766\n",
      "Day 356: Bought 1 share at 258.0199890136719, Cash left: 6099.850036621094\n",
      "Day 357: Bought 1 share at 249.02000427246097, Cash left: 5850.830032348633\n",
      "Day 358: Sold 1 share at 240.66000366210935, Cash: 6091.490036010742\n",
      "Day 360: Sold 1 share at 240.8300018310547, Cash: 6332.320037841797\n",
      "Day 361: Sold 1 share at 244.5, Cash: 6576.820037841797\n",
      "Day 362: Sold 1 share at 241.0500030517578, Cash: 6817.870040893555\n",
      "Day 363: Sold 1 share at 238.77000427246097, Cash: 7056.640045166016\n",
      "Day 364: Sold 1 share at 219.52259826660156, Cash: 7276.162643432617\n",
      "Total cash invested: 10000\n",
      "Stock TSLA\n",
      "Final Portfolio Value: 9032.34342956543\n",
      "Cash: 7276.162643432617, Shares held: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    Stock Name  Day Action         Cash Shares Held  Portfolio Value  \\\n",
       " 0         TSLA    0   Hold        10000           0     10000.000000   \n",
       " 1         TSLA    1   Hold        10000           0     10000.000000   \n",
       " 2         TSLA    2   Hold        10000           0     10000.000000   \n",
       " 3         TSLA    3   Hold        10000           0     10000.000000   \n",
       " 4         TSLA    4   Hold        10000           0     10000.000000   \n",
       " ..         ...  ...    ...          ...         ...              ...   \n",
       " 360       TSLA  360   Sell  6332.320038          12      9222.280060   \n",
       " 361       TSLA  361   Sell  6576.820038          11      9266.320038   \n",
       " 362       TSLA  362   Sell  6817.870041          10      9228.370071   \n",
       " 363       TSLA  363   Sell  7056.640045           9      9205.570084   \n",
       " 364       TSLA  364   Sell  7276.162643           8      9032.343430   \n",
       " \n",
       "      Stock Price       Date  \n",
       " 0     160.309998 2023-05-02  \n",
       " 1     160.610001 2023-05-03  \n",
       " 2     161.199997 2023-05-04  \n",
       " 3     170.059998 2023-05-05  \n",
       " 4     171.789993 2023-05-08  \n",
       " ..           ...        ...  \n",
       " 360   240.830002 2024-10-07  \n",
       " 361   244.500000 2024-10-08  \n",
       " 362   241.050003 2024-10-09  \n",
       " 363   238.770004 2024-10-10  \n",
       " 364   219.522598 2024-10-14  \n",
       " \n",
       " [365 rows x 8 columns],\n",
       " 7276.162643432617)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_model = joblib.load('models/TSLA_model.pkl')\n",
    "# specific_model = train_Optimal_Action(symbol='MSFT', action_column='Action')\n",
    "specificdf = stock_market_simulation(specific_model, 10000, 365, get_stock_data('TSLA').tail(365), print_results=True)\n",
    "specificdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Day</th>\n",
       "      <th>Action</th>\n",
       "      <th>Cash</th>\n",
       "      <th>Shares Held</th>\n",
       "      <th>Portfolio Value</th>\n",
       "      <th>Stock Price</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>0</td>\n",
       "      <td>Buy</td>\n",
       "      <td>9839.690002</td>\n",
       "      <td>1</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>160.309998</td>\n",
       "      <td>2023-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>1</td>\n",
       "      <td>Buy</td>\n",
       "      <td>9679.080002</td>\n",
       "      <td>2</td>\n",
       "      <td>10000.300003</td>\n",
       "      <td>160.610001</td>\n",
       "      <td>2023-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2</td>\n",
       "      <td>Buy</td>\n",
       "      <td>9517.880005</td>\n",
       "      <td>3</td>\n",
       "      <td>10001.479996</td>\n",
       "      <td>161.199997</td>\n",
       "      <td>2023-05-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>3</td>\n",
       "      <td>Hold</td>\n",
       "      <td>9517.880005</td>\n",
       "      <td>3</td>\n",
       "      <td>10028.059998</td>\n",
       "      <td>170.059998</td>\n",
       "      <td>2023-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>4</td>\n",
       "      <td>Hold</td>\n",
       "      <td>9517.880005</td>\n",
       "      <td>3</td>\n",
       "      <td>10033.249985</td>\n",
       "      <td>171.789993</td>\n",
       "      <td>2023-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>360</td>\n",
       "      <td>Sell</td>\n",
       "      <td>240.830002</td>\n",
       "      <td>48.330201</td>\n",
       "      <td>11880.192349</td>\n",
       "      <td>240.830002</td>\n",
       "      <td>2024-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>361</td>\n",
       "      <td>Hold</td>\n",
       "      <td>240.830002</td>\n",
       "      <td>48.330201</td>\n",
       "      <td>12057.564098</td>\n",
       "      <td>244.500000</td>\n",
       "      <td>2024-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>362</td>\n",
       "      <td>Sell</td>\n",
       "      <td>481.880005</td>\n",
       "      <td>47.330201</td>\n",
       "      <td>11890.825052</td>\n",
       "      <td>241.050003</td>\n",
       "      <td>2024-10-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>363</td>\n",
       "      <td>Sell</td>\n",
       "      <td>720.650009</td>\n",
       "      <td>46.330201</td>\n",
       "      <td>11782.912252</td>\n",
       "      <td>238.770004</td>\n",
       "      <td>2024-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>364</td>\n",
       "      <td>Sell</td>\n",
       "      <td>940.310013</td>\n",
       "      <td>45.330201</td>\n",
       "      <td>10897.542087</td>\n",
       "      <td>219.660004</td>\n",
       "      <td>2024-10-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stock Name  Day Action         Cash Shares Held  Portfolio Value  \\\n",
       "0         TSLA    0    Buy  9839.690002           1     10000.000000   \n",
       "1         TSLA    1    Buy  9679.080002           2     10000.300003   \n",
       "2         TSLA    2    Buy  9517.880005           3     10001.479996   \n",
       "3         TSLA    3   Hold  9517.880005           3     10028.059998   \n",
       "4         TSLA    4   Hold  9517.880005           3     10033.249985   \n",
       "..         ...  ...    ...          ...         ...              ...   \n",
       "360       TSLA  360   Sell   240.830002   48.330201     11880.192349   \n",
       "361       TSLA  361   Hold   240.830002   48.330201     12057.564098   \n",
       "362       TSLA  362   Sell   481.880005   47.330201     11890.825052   \n",
       "363       TSLA  363   Sell   720.650009   46.330201     11782.912252   \n",
       "364       TSLA  364   Sell   940.310013   45.330201     10897.542087   \n",
       "\n",
       "     Stock Price       Date  \n",
       "0     160.309998 2023-05-02  \n",
       "1     160.610001 2023-05-03  \n",
       "2     161.199997 2023-05-04  \n",
       "3     170.059998 2023-05-05  \n",
       "4     171.789993 2023-05-08  \n",
       "..           ...        ...  \n",
       "360   240.830002 2024-10-07  \n",
       "361   244.500000 2024-10-08  \n",
       "362   241.050003 2024-10-09  \n",
       "363   238.770004 2024-10-10  \n",
       "364   219.660004 2024-10-14  \n",
       "\n",
       "[365 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simResults['Logistic Regression']\n",
    "simResults['Random Forest']\n",
    "simResults['Stacking']\n",
    "# simResults['SVM']\n",
    "# simResults['XGBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "MODELCOMPARISON = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'SVM', 'XGBoost', 'Specific Model','Stacking',\n",
    "              'Logistic Regression', 'Random Forest', 'SVM', 'XGBoost', 'Specific Model','Stacking',\n",
    "              'Logistic Regression', 'Random Forest', 'SVM', 'XGBoost', 'Specific Model','Stacking',\n",
    "              'Logistic Regression', 'Random Forest', 'SVM', 'XGBoost', 'Specific Model','Stacking',\n",
    "              'Logistic Regression', 'Random Forest', 'SVM', 'XGBoost', 'Specific Model','Stacking',\n",
    "              'Logistic Regression', 'Random Forest', 'SVM', 'XGBoost', 'Specific Model','Stacking',],\n",
    "    'Stock': ['AAPL', 'AAPL', 'AAPL', 'AAPL', 'AAPL','AAPL',\n",
    "              'MSFT', 'MSFT', 'MSFT', 'MSFT', 'MSFT', 'MSFT',\n",
    "              'INTC', 'INTC', 'INTC', 'INTC', 'INTC', 'INTC',\n",
    "              'GOOG', 'GOOG', 'GOOG', 'GOOG', 'GOOG', 'GOOG',\n",
    "              'AMD', 'AMD', 'AMD', 'AMD', 'AMD', 'AMD',\n",
    "              'TSLA', 'TSLA', 'TSLA', 'TSLA', 'TSLA', 'TSLA'],\n",
    "    'Final Portfolio Value': [12010.10, 12438.13, 10991.26, 12404.69, 12404.69, 12560.38,\n",
    "                              11677.37, 11187.02, 11803.34, 11808.35, 11774.20, 10278.36,\n",
    "                              9921.06, 9981.07, 9822.93, 9981.07, 9252.78,9980.80,\n",
    "                              9969.69, 9944.17, 9964.88, 9956.80, 11123.06, 9986.28,\n",
    "                              10187.84, 9921.48, 10446.35, 9921.48, 10742.80,9920.74,\n",
    "                              9144.12, 10501.23, 9193.88, 10614.61, 9016.84,10897.54],\n",
    "    'Total Profit %': [20.01, 24.38, 9.91, 24.04, 24.04, 25.60,\n",
    "                       16.77, 11.87, 18.03, 18.08, 17.74, 2.78,\n",
    "                       -0.79, 0.81, -1.77, 0.81, -7.47, -0.20,\n",
    "                       -0.30, -0.56, -0.35, -0.44, 11.23, -0.14,\n",
    "                       1.19, -0.79, 4.46, -0.79, 7.43, -0.80,\n",
    "                       -8.56, 5.01, -8.06, 6.14, -9.83, 8.98]\n",
    "})\n",
    "MODELCOMPARISON.to_csv('data/MODELCOMPARISON.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Specific Model",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364
         ],
         "xaxis": "x",
         "y": [
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          10000,
          9999.109985351562,
          10003.75,
          10017.66000366211,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10002.669982910156,
          10003.849975585938,
          10003.849975585938,
          10015.329971313477,
          10010.759979248047,
          10009.899993896484,
          10006.90998840332,
          10006.90998840332,
          10006.90998840332,
          10010.729965209961,
          10015.469985961914,
          10013.81999206543,
          10013.81999206543,
          10013.81999206543,
          10013.81999206543,
          10013.81999206543,
          10013.81999206543,
          10013.81999206543,
          10013.81999206543,
          10013.81999206543,
          10013.81999206543,
          10013.81999206543,
          10013.81999206543,
          10013.81999206543,
          10013.81999206543,
          10013.81999206543,
          10013.81999206543,
          10013.81999206543,
          10013.81999206543,
          10013.189987182617,
          10004.949996948242,
          9981.699996948242,
          9987.300003051758,
          9988.230010986328,
          9988.230010986328,
          9988.230010986328,
          9988.230010986328,
          9988.230010986328,
          9988.230010986328,
          9988.230010986328,
          9988.230010986328,
          9988.230010986328,
          9988.230010986328,
          9988.230010986328,
          9988.230010986328,
          9988.230010986328,
          9988.230010986328,
          9988.230010986328,
          9988.230010986328,
          9988.160018920898,
          9963.900009155273,
          9977.91000366211,
          10014.15005493164,
          10068.95004272461,
          10090.670013427734,
          10053.670013427734,
          10057.22004699707,
          10065.020065307617,
          10104.220001220703,
          10048.300079345703,
          10059.459991455078,
          10065.760040283203,
          10182.800033569336,
          10154.420013427734,
          10105.70004272461,
          10089.45004272461,
          10043.95004272461,
          10091.050033569336,
          10100.149948120117,
          10142.66000366211,
          10157.059967041016,
          10111.960067749023,
          10084.659957885742,
          10105.179946899414,
          10199.260025024414,
          10216.41000366211,
          10205.050018310547,
          10251.310012817383,
          10160.58999633789,
          10219.470001220703,
          10205.749954223633,
          10230.169906616211,
          10263.980026245117,
          10206.159957885742,
          10177.959976196289,
          10177.65998840332,
          10137.779983520508,
          10136.219970703125,
          10135.33999633789,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10138.299987792969,
          10132.859985351562,
          10124.63998413086,
          10138.709991455078,
          10185.669952392578,
          10183.669952392578,
          10152.719940185547,
          10158.779998779297,
          10177.259994506836,
          10133.739974975586,
          10200.609909057617,
          10203.909927368164,
          10229.319900512695,
          10227.400039672852,
          10237.279968261719,
          10034.279968261719,
          9923.280059814453,
          9856.079864501953,
          9887.729873657227,
          9838.07991027832,
          9872.100021362305,
          9868.879867553711,
          9764.099899291992,
          9680.339950561523,
          9692.11003112793,
          9794.40998840332,
          9769.61003112793,
          9808.669998168945,
          9785.95002746582,
          9768.039978027344,
          9782.440002441406,
          9817.719955444336,
          9832.839981079102,
          9800.519912719727,
          9795.38998413086,
          9709.490020751953,
          9728.740020751953,
          9756.039978027344,
          9700.149917602539,
          9780.949935913086,
          9819.95002746582,
          9773.869934082031,
          9802.270050048828,
          9770.320022583008,
          9674.61994934082,
          9635.289993286133,
          9622.009963989258,
          9583.369934082031,
          9566.08999633789,
          9541.08999633789,
          9551.609954833984,
          9603.959991455078,
          9628.109954833984,
          9622.439956665039,
          9725.479995727539,
          9682.399978637695,
          9665.950012207031,
          9666.069946289062,
          9674.330001831055,
          9702.889938354492,
          9640.339965820312,
          9609.440002441406,
          9579.190002441406,
          9537.190002441406,
          9581.649978637695,
          9655.230026245117,
          9612.510055541992,
          9623.559936523438,
          9657.620071411133,
          9627.499954223633,
          9755.65005493164,
          9684.259994506836,
          9607.820053100586,
          9668.320053100586,
          9640.929992675781,
          9634.210021972656,
          9662.809921264648,
          9655.710006713867,
          9639.59992980957,
          9627.440017700195,
          9629.509979248047,
          9653.029998779297,
          9649.809951782227,
          9627.669937133789,
          9612.019989013672,
          9638.539947509766,
          9654.079971313477,
          9645.159957885742,
          9654.589965820312,
          9654.589965820312,
          9651.29997253418,
          9651.29997253418,
          9650.869979858398,
          9650.869979858398,
          9650.869979858398,
          9651.919982910156,
          9652.83999633789,
          9688.779983520508,
          9774.379959106445,
          9850.029983520508,
          9880.810012817383,
          9890.75,
          9965.869873046875,
          9974.24008178711,
          9751.939971923828,
          9831.139938354492,
          9879.649978637695,
          9926.689956665039,
          9821.90998840332,
          9832.129928588867,
          9681.679946899414,
          9878.639907836914,
          9796.560073852539,
          9340.710083007812,
          9400.350006103516,
          9394.050048828125,
          9553.950088500977,
          9430.709945678711,
          9544.110092163086,
          9361.59001159668,
          9260.499984741211,
          9172.600051879883,
          9188.440002441406,
          9117.399963378906,
          9166.959976196289,
          9175.080001831055,
          9160.020034790039,
          9211.720016479492,
          9179.470031738281,
          9230.510009765625,
          9238.429992675781,
          9258.230010986328,
          9253.370025634766,
          9262.050018310547,
          9199.000015258789,
          9256.960037231445,
          9214.300033569336,
          9186.300033569336,
          9165.539993286133,
          9168.189987182617,
          9199.509994506836,
          9185.470016479492,
          9211.900009155273,
          9244.179992675781,
          9185.859985351562,
          9208.02001953125,
          9237.720001220703,
          9243.600021362305,
          9246.960006713867,
          9248.399993896484,
          9234.36001586914,
          9239.809997558594,
          9236.460006713867,
          9336.780014038086,
          9302.760025024414,
          9385.010025024414,
          9419.170059204102,
          9443.919921875,
          9415.920043945312,
          9484.559936523438,
          9497.430084228516,
          9454.109893798828,
          9337.110092163086,
          9220.070083618164,
          9342.530059814453,
          9222.280059814453,
          9266.320037841797,
          9228.370071411133,
          9205.570083618164,
          9016.840072631836
         ],
         "yaxis": "y"
        },
        {
         "mode": "lines",
         "name": "Stock Price",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364
         ],
         "xaxis": "x2",
         "y": [
          160.30999755859375,
          160.61000061035156,
          161.1999969482422,
          170.05999755859375,
          171.7899932861328,
          169.14999389648438,
          168.5399932861328,
          172.0800018310547,
          167.97999572753906,
          166.35000610351562,
          166.52000427246094,
          173.86000061035156,
          176.88999938964844,
          180.13999938964844,
          188.8699951171875,
          185.77000427246097,
          182.8999938964844,
          184.47000122070312,
          193.1699981689453,
          201.16000366210935,
          203.92999267578125,
          207.52000427246097,
          213.97000122070312,
          217.61000061035156,
          221.30999755859375,
          224.57000732421875,
          234.86000061035156,
          244.3999938964844,
          249.8300018310547,
          258.7099914550781,
          256.7900085449219,
          255.8999938964844,
          260.5400085449219,
          274.45001220703125,
          259.4599914550781,
          264.6099853515625,
          256.6000061035156,
          241.0500030517578,
          250.2100067138672,
          256.239990234375,
          257.5,
          261.7699890136719,
          279.82000732421875,
          282.4800109863281,
          276.5400085449219,
          274.42999267578125,
          269.6099853515625,
          269.7900085449219,
          271.989990234375,
          277.8999938964844,
          281.3800048828125,
          290.3800048828125,
          293.3399963378906,
          291.260009765625,
          262.8999938964844,
          260.0199890136719,
          269.05999755859375,
          265.2799987792969,
          264.3500061035156,
          255.7100067138672,
          266.44000244140625,
          267.42999267578125,
          261.07000732421875,
          254.11000061035156,
          259.32000732421875,
          253.86000061035156,
          251.4499969482422,
          249.6999969482422,
          242.19000244140625,
          245.33999633789065,
          242.6499938964844,
          239.7599945068359,
          232.9600067138672,
          225.6000061035156,
          219.22000122070312,
          215.4900054931641,
          231.27999877929688,
          233.19000244140625,
          236.86000061035156,
          230.0399932861328,
          238.58999633789065,
          238.82000732421875,
          257.17999267578125,
          256.8999938964844,
          258.0799865722656,
          245.0099945068359,
          256.489990234375,
          251.9199981689453,
          251.4900054931641,
          248.5,
          273.5799865722656,
          267.4800109863281,
          271.29998779296875,
          276.0400085449219,
          274.3900146484375,
          265.2799987792969,
          266.5,
          262.5899963378906,
          255.6999969482422,
          244.8800048828125,
          246.9900054931641,
          244.1199951171875,
          240.5,
          246.3800048828125,
          250.22000122070312,
          251.6000061035156,
          246.52999877929688,
          261.1600036621094,
          260.04998779296875,
          260.5299987792969,
          259.6700134277344,
          263.6199951171875,
          262.989990234375,
          258.8699951171875,
          251.1199951171875,
          253.9199981689453,
          254.8500061035156,
          242.67999267578125,
          220.11000061035156,
          211.9900054931641,
          212.0800018310547,
          216.52000427246097,
          212.4199981689453,
          205.7599945068359,
          207.3000030517578,
          197.36000061035156,
          200.83999633789065,
          205.66000366210935,
          218.5099945068359,
          219.9600067138672,
          219.27000427246097,
          222.17999267578125,
          222.11000061035156,
          209.97999572753903,
          214.6499938964844,
          223.7100067138672,
          237.41000366210935,
          242.83999633789065,
          233.58999633789065,
          234.3000030517578,
          235.6000061035156,
          241.1999969482422,
          234.2100067138672,
          235.4499969482422,
          236.0800018310547,
          246.72000122070312,
          244.13999938964844,
          240.0800018310547,
          238.8300018310547,
          235.5800018310547,
          238.72000122070312,
          239.3699951171875,
          242.63999938964844,
          243.83999633789065,
          239.7400054931641,
          237.0099945068359,
          239.2899932861328,
          251.0500030517578,
          253.5,
          252.0800018310547,
          257.2200012207031,
          247.13999938964844,
          254.5,
          252.5399932861328,
          256.6099853515625,
          261.44000244140625,
          253.17999267578125,
          248.47999572753903,
          248.4199981689453,
          238.4499969482422,
          237.92999267578125,
          237.4900054931641,
          240.4499969482422,
          234.9600067138672,
          233.94000244140625,
          227.22000122070312,
          218.88999938964844,
          219.91000366210935,
          215.5500030517578,
          211.8800048828125,
          212.19000244140625,
          208.8000030517578,
          209.13999938964844,
          207.8300018310547,
          182.6300048828125,
          183.25,
          190.92999267578125,
          191.58999633789065,
          187.2899932861328,
          188.86000061035156,
          187.91000366210935,
          181.05999755859375,
          185.1000061035156,
          187.5800018310547,
          189.55999755859375,
          193.57000732421875,
          188.1300048828125,
          184.02000427246097,
          188.7100067138672,
          200.4499969482422,
          199.9499969482422,
          193.7599945068359,
          194.77000427246097,
          197.41000366210935,
          191.97000122070312,
          199.3999938964844,
          199.72999572753903,
          202.0399932861328,
          201.8800048828125,
          202.63999938964844,
          188.13999938964844,
          180.7400054931641,
          176.5399932861328,
          178.64999389648438,
          175.33999633789062,
          177.77000427246094,
          177.5399932861328,
          169.47999572753906,
          162.5,
          163.57000732421875,
          173.8000030517578,
          171.32000732421875,
          175.66000366210938,
          172.82000732421875,
          170.8300018310547,
          172.6300048828125,
          177.6699981689453,
          179.8300018310547,
          175.7899932861328,
          175.22000122070312,
          166.6300048828125,
          168.3800048828125,
          171.11000061035156,
          164.89999389648438,
          172.97999572753906,
          176.8800048828125,
          171.75999450683594,
          174.60000610351562,
          171.0500030517578,
          161.47999572753906,
          157.11000061035156,
          155.4499969482422,
          149.92999267578125,
          147.0500030517578,
          142.0500030517578,
          144.67999267578125,
          162.1300048828125,
          170.17999267578125,
          168.2899932861328,
          194.0500030517578,
          183.27999877929688,
          179.99000549316406,
          180.00999450683594,
          181.19000244140625,
          184.7599945068359,
          177.80999755859375,
          174.72000122070312,
          171.97000122070312,
          168.47000122070312,
          171.88999938964844,
          177.5500030517578,
          173.99000549316406,
          174.83999633789062,
          177.4600067138672,
          174.9499969482422,
          186.6000061035156,
          180.11000061035156,
          173.74000549316406,
          179.24000549316406,
          176.75,
          176.19000244140625,
          178.7899932861328,
          178.0800018310547,
          176.2899932861328,
          174.77000427246094,
          175,
          177.94000244140625,
          177.47999572753906,
          173.7899932861328,
          170.66000366210938,
          177.2899932861328,
          182.47000122070312,
          178.00999450683594,
          187.44000244140625,
          184.86000061035156,
          181.57000732421875,
          183.0099945068359,
          182.5800018310547,
          187.3500061035156,
          196.3699951171875,
          197.4199981689453,
          197.8800048828125,
          209.86000061035156,
          231.2599945068359,
          246.38999938964844,
          251.52000427246097,
          252.94000244140625,
          262.3299865722656,
          263.260009765625,
          241.02999877929688,
          248.22999572753903,
          252.63999938964844,
          256.55999755859375,
          248.5,
          249.22999572753903,
          239.1999969482422,
          251.5099945068359,
          246.3800048828125,
          215.9900054931641,
          220.25,
          219.8000030517578,
          232.1000061035156,
          222.6199951171875,
          232.07000732421875,
          216.86000061035156,
          207.6699981689453,
          198.8800048828125,
          200.63999938964844,
          191.7599945068359,
          198.83999633789065,
          200,
          197.4900054931641,
          207.8300018310547,
          201.3800048828125,
          214.13999938964844,
          216.1199951171875,
          222.72000122070312,
          221.1000061035156,
          223.27000427246097,
          210.66000366210935,
          220.32000732421875,
          213.2100067138672,
          209.2100067138672,
          205.75,
          206.27999877929688,
          214.11000061035156,
          210.6000061035156,
          219.41000366210935,
          230.1699981689453,
          210.72999572753903,
          216.27000427246097,
          226.1699981689453,
          228.1300048828125,
          229.80999755859375,
          230.2899932861328,
          226.77999877929688,
          227.8699951171875,
          227.1999969482422,
          243.9199981689453,
          238.25,
          250,
          254.27000427246097,
          257.0199890136719,
          254.22000122070312,
          260.4599914550781,
          261.6300048828125,
          258.0199890136719,
          249.02000427246097,
          240.66000366210935,
          250.0800018310547,
          240.8300018310547,
          244.5,
          241.0500030517578,
          238.77000427246097,
          217.8000030517578
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Final Portfolio Value",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Stock Price",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 600,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Portfolio Analysis"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "matches": "x2",
         "showticklabels": false
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          0.375
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create subplots with 2 rows and 1 column\n",
    "fig = sp.make_subplots(rows=2, cols=1, subplot_titles=('Final Portfolio Value', 'Stock Price'), shared_xaxes=True)\n",
    "\n",
    "# Add trace for Portfolio Value in the first row\n",
    "fig.add_trace(go.Scatter(x=specificdf[0]['Day'], y=specificdf[0]['Portfolio Value'],mode='lines', name='Specific Model'), row=1, col=1)\n",
    "\n",
    "# Add trace for Stock Price in the first row\n",
    "fig.add_trace(go.Scatter(x=specificdf[0]['Day'], y=specificdf[0]['Stock Price'], mode='lines', name='Stock Price'), row=2, col=1)\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(height=600, width=800, title_text=\"Portfolio Analysis\")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Day</th>\n",
       "      <th>Action</th>\n",
       "      <th>Cash</th>\n",
       "      <th>Shares Held</th>\n",
       "      <th>Portfolio Value</th>\n",
       "      <th>Stock Price</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>0</td>\n",
       "      <td>Hold</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>160.309998</td>\n",
       "      <td>2023-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>1</td>\n",
       "      <td>Hold</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>160.610001</td>\n",
       "      <td>2023-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2</td>\n",
       "      <td>Hold</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>161.199997</td>\n",
       "      <td>2023-05-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>3</td>\n",
       "      <td>Hold</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>170.059998</td>\n",
       "      <td>2023-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>4</td>\n",
       "      <td>Hold</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>171.789993</td>\n",
       "      <td>2023-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>360</td>\n",
       "      <td>Sell</td>\n",
       "      <td>6332.320038</td>\n",
       "      <td>12</td>\n",
       "      <td>9222.280060</td>\n",
       "      <td>240.830002</td>\n",
       "      <td>2024-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>361</td>\n",
       "      <td>Sell</td>\n",
       "      <td>6576.820038</td>\n",
       "      <td>11</td>\n",
       "      <td>9266.320038</td>\n",
       "      <td>244.500000</td>\n",
       "      <td>2024-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>362</td>\n",
       "      <td>Sell</td>\n",
       "      <td>6817.870041</td>\n",
       "      <td>10</td>\n",
       "      <td>9228.370071</td>\n",
       "      <td>241.050003</td>\n",
       "      <td>2024-10-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>363</td>\n",
       "      <td>Sell</td>\n",
       "      <td>7056.640045</td>\n",
       "      <td>9</td>\n",
       "      <td>9205.570084</td>\n",
       "      <td>238.770004</td>\n",
       "      <td>2024-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>364</td>\n",
       "      <td>Sell</td>\n",
       "      <td>7274.440048</td>\n",
       "      <td>8</td>\n",
       "      <td>9016.840073</td>\n",
       "      <td>217.800003</td>\n",
       "      <td>2024-10-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stock Name  Day Action         Cash Shares Held  Portfolio Value  \\\n",
       "0         TSLA    0   Hold        10000           0     10000.000000   \n",
       "1         TSLA    1   Hold        10000           0     10000.000000   \n",
       "2         TSLA    2   Hold        10000           0     10000.000000   \n",
       "3         TSLA    3   Hold        10000           0     10000.000000   \n",
       "4         TSLA    4   Hold        10000           0     10000.000000   \n",
       "..         ...  ...    ...          ...         ...              ...   \n",
       "360       TSLA  360   Sell  6332.320038          12      9222.280060   \n",
       "361       TSLA  361   Sell  6576.820038          11      9266.320038   \n",
       "362       TSLA  362   Sell  6817.870041          10      9228.370071   \n",
       "363       TSLA  363   Sell  7056.640045           9      9205.570084   \n",
       "364       TSLA  364   Sell  7274.440048           8      9016.840073   \n",
       "\n",
       "     Stock Price       Date  \n",
       "0     160.309998 2023-05-02  \n",
       "1     160.610001 2023-05-03  \n",
       "2     161.199997 2023-05-04  \n",
       "3     170.059998 2023-05-05  \n",
       "4     171.789993 2023-05-08  \n",
       "..           ...        ...  \n",
       "360   240.830002 2024-10-07  \n",
       "361   244.500000 2024-10-08  \n",
       "362   241.050003 2024-10-09  \n",
       "363   238.770004 2024-10-10  \n",
       "364   217.800003 2024-10-11  \n",
       "\n",
       "[365 rows x 8 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificdf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:238: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  '10_Day_Return', '20_Day_Return', '50_Day_Return', '200_Day_Return']].idxmax(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-11 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-11 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-11 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-11 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-11 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;rf&#x27;, RandomForestClassifier(random_state=42)),\n",
       "                               (&#x27;xgb&#x27;,\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_t...\n",
       "                                                 feature_types=None, gamma=None,\n",
       "                                                 grow_policy=None,\n",
       "                                                 importance_type=None,\n",
       "                                                 interaction_constraints=None,\n",
       "                                                 learning_rate=None,\n",
       "                                                 max_bin=None,\n",
       "                                                 max_cat_threshold=None,\n",
       "                                                 max_cat_to_onehot=None,\n",
       "                                                 max_delta_step=None,\n",
       "                                                 max_depth=None,\n",
       "                                                 max_leaves=None,\n",
       "                                                 min_child_weight=None,\n",
       "                                                 missing=nan,\n",
       "                                                 monotone_constraints=None,\n",
       "                                                 multi_strategy=None,\n",
       "                                                 n_estimators=100, n_jobs=None,\n",
       "                                                 num_parallel_tree=None,\n",
       "                                                 random_state=42, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;StackingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.StackingClassifier.html\">?<span>Documentation for StackingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>StackingClassifier(estimators=[(&#x27;rf&#x27;, RandomForestClassifier(random_state=42)),\n",
       "                               (&#x27;xgb&#x27;,\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_t...\n",
       "                                                 feature_types=None, gamma=None,\n",
       "                                                 grow_policy=None,\n",
       "                                                 importance_type=None,\n",
       "                                                 interaction_constraints=None,\n",
       "                                                 learning_rate=None,\n",
       "                                                 max_bin=None,\n",
       "                                                 max_cat_threshold=None,\n",
       "                                                 max_cat_to_onehot=None,\n",
       "                                                 max_delta_step=None,\n",
       "                                                 max_depth=None,\n",
       "                                                 max_leaves=None,\n",
       "                                                 min_child_weight=None,\n",
       "                                                 missing=nan,\n",
       "                                                 monotone_constraints=None,\n",
       "                                                 multi_strategy=None,\n",
       "                                                 n_estimators=100, n_jobs=None,\n",
       "                                                 num_parallel_tree=None,\n",
       "                                                 random_state=42, ...))</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(estimators=[('rf', RandomForestClassifier(random_state=42)),\n",
       "                               ('xgb',\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              device=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              grow_policy=None,\n",
       "                                              importance_t...\n",
       "                                                 feature_types=None, gamma=None,\n",
       "                                                 grow_policy=None,\n",
       "                                                 importance_type=None,\n",
       "                                                 interaction_constraints=None,\n",
       "                                                 learning_rate=None,\n",
       "                                                 max_bin=None,\n",
       "                                                 max_cat_threshold=None,\n",
       "                                                 max_cat_to_onehot=None,\n",
       "                                                 max_delta_step=None,\n",
       "                                                 max_depth=None,\n",
       "                                                 max_leaves=None,\n",
       "                                                 min_child_weight=None,\n",
       "                                                 missing=nan,\n",
       "                                                 monotone_constraints=None,\n",
       "                                                 multi_strategy=None,\n",
       "                                                 n_estimators=100, n_jobs=None,\n",
       "                                                 num_parallel_tree=None,\n",
       "                                                 random_state=42, ...))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stock_df = get_stock_data('TSLA')\n",
    "# print(f'Adding columns...')\n",
    "stock_df = pd.read_csv('data/sp500_stocks.csv')\n",
    "stock_df = stock_df[stock_df['Symbol'] == 'AAPL']\n",
    "print(f'Scaling data...')\n",
    "preprocessed = scale_data(stock_df)\n",
    "X = preprocessed[features]\n",
    "y = stock_df['Action']\n",
    "# y = y.map({'Buy': 0, 'Sell': 1, 'Hold': 2})\n",
    "X_train, _, y_train, _ = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "        ('xgb', xgb.XGBClassifier(n_estimators=100, random_state=42)),\n",
    "        # (\"specificModel\", joblib.load('models/MSFT_model.pkl'))\n",
    "    ],\n",
    "    final_estimator=xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:238: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  '10_Day_Return', '20_Day_Return', '50_Day_Return', '200_Day_Return']].idxmax(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 0: Bought 1 share at 168.5399932861328, Cash left: 9831.460006713867\n",
      "Day 1: Bought 1 share at 167.4499969482422, Cash left: 9664.010009765625\n",
      "Day 2: Bought 1 share at 165.7899932861328, Cash left: 9498.220016479492\n",
      "Day 4: Bought 1 share at 173.5, Cash left: 9324.720016479492\n",
      "Day 5: Bought 1 share at 171.77000427246094, Cash left: 9152.950012207031\n",
      "Day 6: Bought 1 share at 173.55999755859375, Cash left: 8979.390014648438\n",
      "Day 7: Bought 1 share at 173.75, Cash left: 8805.640014648438\n",
      "Day 8: Bought 1 share at 172.57000732421875, Cash left: 8633.070007324219\n",
      "Day 9: Bought 1 share at 172.07000732421875, Cash left: 8461.0\n",
      "Day 10: Bought 1 share at 172.07000732421875, Cash left: 8288.929992675781\n",
      "Day 11: Bought 1 share at 172.69000244140625, Cash left: 8116.239990234375\n",
      "Day 12: Bought 1 share at 175.0500030517578, Cash left: 7941.189987182617\n",
      "Day 13: Bought 1 share at 175.16000366210938, Cash left: 7766.029983520508\n",
      "Day 14: Bought 1 share at 174.1999969482422, Cash left: 7591.829986572266\n",
      "Day 15: Bought 1 share at 171.55999755859375, Cash left: 7420.269989013672\n",
      "Day 16: Bought 1 share at 171.83999633789062, Cash left: 7248.429992675781\n",
      "Day 17: Bought 1 share at 172.99000549316406, Cash left: 7075.439987182617\n",
      "Day 18: Bought 1 share at 175.42999267578125, Cash left: 6900.009994506836\n",
      "Day 19: Bought 1 share at 177.3000030517578, Cash left: 6722.709991455078\n",
      "Day 20: Bought 1 share at 177.25, Cash left: 6545.459991455078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardobenjamin/Desktop/Repos/MachineLearningProjects/Stock-Market-Analysis+Model/SimulateDay.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  modelDecisionDf = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 21: Bought 1 share at 180.08999633789062, Cash left: 6365.3699951171875\n",
      "Day 22: Bought 1 share at 180.9499969482422, Cash left: 6184.419998168945\n",
      "Day 23: Bought 1 share at 179.5800018310547, Cash left: 6004.839996337891\n",
      "Day 24: Bought 1 share at 179.2100067138672, Cash left: 5825.629989624023\n",
      "Day 25: Bought 1 share at 177.82000732421875, Cash left: 5647.809982299805\n",
      "Day 26: Bought 1 share at 180.57000732421875, Cash left: 5467.239974975586\n",
      "Day 27: Bought 1 share at 180.9600067138672, Cash left: 5286.279968261719\n",
      "Day 28: Bought 1 share at 183.7899932861328, Cash left: 5102.489974975586\n",
      "Day 29: Bought 1 share at 183.30999755859375, Cash left: 4919.179977416992\n",
      "Day 30: Bought 1 share at 183.9499969482422, Cash left: 4735.22998046875\n",
      "Day 31: Bought 1 share at 186.0099945068359, Cash left: 4549.219985961914\n",
      "Day 32: Bought 1 share at 184.9199981689453, Cash left: 4364.299987792969\n",
      "Day 33: Bought 1 share at 185.0099945068359, Cash left: 4179.289993286133\n",
      "Day 34: Bought 1 share at 183.9600067138672, Cash left: 3995.3299865722656\n",
      "Day 35: Bought 1 share at 187.0, Cash left: 3808.3299865722656\n",
      "Day 36: Bought 1 share at 186.67999267578125, Cash left: 3621.6499938964844\n",
      "Day 37: Bought 1 share at 185.27000427246097, Cash left: 3436.3799896240234\n",
      "Day 38: Bought 1 share at 188.05999755859375, Cash left: 3248.3199920654297\n",
      "Day 39: Bought 1 share at 189.25, Cash left: 3059.0699920654297\n",
      "Day 40: Bought 1 share at 189.58999633789065, Cash left: 2869.479995727539\n",
      "Day 42: Bought 1 share at 192.4600067138672, Cash left: 2677.019989013672\n",
      "Day 43: Bought 1 share at 191.3300018310547, Cash left: 2485.689987182617\n",
      "Day 44: Bought 1 share at 191.80999755859375, Cash left: 2293.8799896240234\n",
      "Day 45: Bought 1 share at 190.67999267578125, Cash left: 2103.199996948242\n",
      "Day 46: Bought 1 share at 188.61000061035156, Cash left: 1914.5899963378906\n",
      "Day 47: Bought 1 share at 188.0800018310547, Cash left: 1726.509994506836\n",
      "Day 48: Bought 1 share at 189.77000427246097, Cash left: 1536.739990234375\n",
      "Day 49: Sold 1 share at 190.5399932861328, Cash: 1727.2799835205078\n",
      "Day 50: Sold 1 share at 190.69000244140625, Cash: 1917.969985961914\n",
      "Day 51: Bought 1 share at 193.9900054931641, Cash left: 1723.97998046875\n",
      "Day 52: Bought 1 share at 193.72999572753903, Cash left: 1530.249984741211\n",
      "Day 53: Bought 1 share at 195.1000061035156, Cash left: 1335.1499786376953\n",
      "Day 54: Bought 1 share at 193.1300048828125, Cash left: 1142.0199737548828\n",
      "Day 55: Bought 1 share at 191.94000244140625, Cash left: 950.0799713134766\n",
      "Day 56: Bought 1 share at 192.75, Cash left: 757.3299713134766\n",
      "Day 57: Sold 1 share at 193.6199951171875, Cash: 950.9499664306641\n",
      "Day 58: Bought 1 share at 194.5, Cash left: 756.4499664306641\n",
      "Day 59: Bought 1 share at 193.22000122070312, Cash left: 563.2299652099609\n",
      "Day 60: Bought 1 share at 195.8300018310547, Cash left: 367.39996337890625\n",
      "Day 61: Bought 1 share at 196.4499969482422, Cash left: 170.94996643066406\n",
      "Day 62: Bought 0.0 shares at 195.61000061035156, Cash left: 0\n",
      "Day 63: Sold 1 share at 192.5800018310547, Cash: 192.5800018310547\n",
      "Day 64: Sold 1 share at 191.1699981689453, Cash: 383.75\n",
      "Day 65: Sold 1 share at 181.9900054931641, Cash: 565.7400054931641\n",
      "Day 66: Sold 1 share at 178.85000610351562, Cash: 744.5900115966797\n",
      "Day 67: Sold 1 share at 179.8000030517578, Cash: 924.3900146484375\n",
      "Day 68: Sold 1 share at 178.19000244140625, Cash: 1102.5800170898438\n",
      "Day 69: Sold 1 share at 177.97000122070312, Cash: 1280.5500183105469\n",
      "Day 70: Sold 1 share at 177.7899932861328, Cash: 1458.3400115966797\n",
      "Day 71: Sold 1 share at 179.4600067138672, Cash: 1637.8000183105469\n",
      "Day 72: Sold 1 share at 177.4499969482422, Cash: 1815.250015258789\n",
      "Day 73: Sold 1 share at 176.57000732421875, Cash: 1991.8200225830078\n",
      "Day 74: Sold 1 share at 174.0, Cash: 2165.820022583008\n",
      "Day 75: Sold 1 share at 174.49000549316406, Cash: 2340.310028076172\n",
      "Day 76: Sold 1 share at 175.83999633789062, Cash: 2516.1500244140625\n",
      "Day 77: Sold 1 share at 177.22999572753906, Cash: 2693.3800201416016\n",
      "Day 79: Bought 1 share at 176.3800048828125, Cash left: 2517.000015258789\n",
      "Day 80: Bought 1 share at 178.61000061035156, Cash left: 2338.3900146484375\n",
      "Day 81: Bought 1 share at 180.19000244140625, Cash left: 2158.2000122070312\n",
      "Day 83: Bought 1 share at 187.6499938964844, Cash left: 1970.5500183105469\n",
      "Day 84: Bought 1 share at 187.8699951171875, Cash left: 1782.6800231933594\n",
      "Day 85: Bought 1 share at 189.4600067138672, Cash left: 1593.2200164794922\n",
      "Day 86: Bought 1 share at 189.6999969482422, Cash left: 1403.52001953125\n",
      "Day 87: Bought 1 share at 182.91000366210935, Cash left: 1220.6100158691406\n",
      "Day 88: Bought 1 share at 177.55999755859375, Cash left: 1043.0500183105469\n",
      "Day 89: Bought 1 share at 178.17999267578125, Cash left: 864.8700256347656\n",
      "Day 90: Bought 1 share at 179.36000061035156, Cash left: 685.5100250244141\n",
      "Day 91: Sold 1 share at 176.3000030517578, Cash: 861.8100280761719\n",
      "Day 92: Sold 1 share at 174.2100067138672, Cash: 1036.020034790039\n",
      "Day 93: Sold 1 share at 175.74000549316406, Cash: 1211.7600402832031\n",
      "Day 94: Sold 1 share at 175.00999450683594, Cash: 1386.770034790039\n",
      "Day 95: Sold 1 share at 177.97000122070312, Cash: 1564.7400360107422\n",
      "Day 96: Bought 1 share at 179.07000732421875, Cash left: 1385.6700286865234\n",
      "Day 97: Sold 1 share at 175.49000549316406, Cash: 1561.1600341796875\n",
      "Day 98: Sold 1 share at 173.92999267578125, Cash: 1735.0900268554688\n",
      "Day 99: Sold 1 share at 174.7899932861328, Cash: 1909.8800201416016\n",
      "Day 100: Bought 1 share at 176.0800018310547, Cash left: 1733.8000183105469\n",
      "Day 101: Sold 1 share at 171.9600067138672, Cash: 1905.760025024414\n",
      "Day 102: Sold 1 share at 170.42999267578125, Cash: 2076.1900177001953\n",
      "Day 103: Sold 1 share at 170.69000244140625, Cash: 2246.8800201416016\n",
      "Day 104: Sold 1 share at 171.2100067138672, Cash: 2418.0900268554688\n",
      "Day 105: Sold 1 share at 173.75, Cash: 2591.8400268554688\n",
      "Day 106: Bought 1 share at 172.39999389648438, Cash left: 2419.4400329589844\n",
      "Day 107: Bought 1 share at 173.66000366210938, Cash left: 2245.780029296875\n",
      "Day 108: Bought 1 share at 174.91000366210938, Cash left: 2070.8700256347656\n",
      "Day 109: Bought 1 share at 177.49000549316406, Cash left: 1893.3800201416016\n",
      "Day 110: Bought 1 share at 178.99000549316406, Cash left: 1714.3900146484375\n",
      "Day 111: Bought 1 share at 178.38999938964844, Cash left: 1536.000015258789\n",
      "Day 112: Bought 1 share at 179.8000030517578, Cash left: 1356.2000122070312\n",
      "Day 113: Bought 1 share at 180.7100067138672, Cash left: 1175.490005493164\n",
      "Day 114: Bought 1 share at 178.85000610351562, Cash left: 996.6399993896484\n",
      "Day 115: Bought 1 share at 178.72000122070312, Cash left: 817.9199981689453\n",
      "Day 116: Bought 1 share at 177.14999389648438, Cash left: 640.7700042724609\n",
      "Day 117: Bought 1 share at 175.83999633789062, Cash left: 464.9300079345703\n",
      "Day 118: Bought 1 share at 175.4600067138672, Cash left: 289.4700012207031\n",
      "Day 119: Bought 1 share at 172.8800048828125, Cash left: 116.58999633789062\n",
      "Day 120: Bought 0.0 shares at 173.0, Cash left: 0\n",
      "Day 121: Sold 1 share at 173.44000244140625, Cash: 173.44000244140625\n",
      "Day 122: Sold 1 share at 171.10000610351562, Cash: 344.5400085449219\n",
      "Day 123: Sold 1 share at 166.88999938964844, Cash: 511.4300079345703\n",
      "Day 124: Sold 1 share at 168.22000122070312, Cash: 679.6500091552734\n",
      "Day 125: Sold 1 share at 170.2899932861328, Cash: 849.9400024414062\n",
      "Day 126: Sold 1 share at 170.77000427246094, Cash: 1020.7100067138672\n",
      "Day 127: Bought 1 share at 173.97000122070312, Cash left: 846.7400054931641\n",
      "Day 129: Bought 1 share at 176.64999389648438, Cash left: 670.0900115966797\n",
      "Day 130: Bought 1 share at 179.22999572753906, Cash left: 490.8600158691406\n",
      "Day 131: Bought 1 share at 181.82000732421875, Cash left: 309.0400085449219\n",
      "Day 132: Bought 1 share at 182.88999938964844, Cash left: 126.15000915527344\n",
      "Day 133: Bought 0.0 shares at 182.41000366210935, Cash left: 0\n",
      "Day 135: Bought 0.0 shares at 184.8000030517578, Cash left: 0\n",
      "Day 136: Bought 0.0 shares at 187.44000244140625, Cash left: 0\n",
      "Day 137: Bought 0.0 shares at 188.0099945068359, Cash left: 0\n",
      "Day 138: Bought 0.0 shares at 189.7100067138672, Cash left: 0\n",
      "Day 139: Bought 0.0 shares at 189.69000244140625, Cash left: 0\n",
      "Day 140: Bought 0.0 shares at 191.4499969482422, Cash left: 0\n",
      "Day 141: Bought 0.0 shares at 190.63999938964844, Cash left: 0\n",
      "Day 142: Bought 0.0 shares at 191.30999755859375, Cash left: 0\n",
      "Day 143: Bought 0.0 shares at 189.97000122070312, Cash left: 0\n",
      "Day 144: Bought 0.0 shares at 189.7899932861328, Cash left: 0\n",
      "Day 145: Bought 0.0 shares at 190.3999938964844, Cash left: 0\n",
      "Day 146: Bought 0.0 shares at 189.3699951171875, Cash left: 0\n",
      "Day 147: Bought 0.0 shares at 189.9499969482422, Cash left: 0\n",
      "Day 148: Bought 0.0 shares at 191.2400054931641, Cash left: 0\n",
      "Day 149: Bought 0.0 shares at 189.42999267578125, Cash left: 0\n",
      "Day 151: Bought 0.0 shares at 192.32000732421875, Cash left: 0\n",
      "Day 152: Bought 0.0 shares at 194.27000427246097, Cash left: 0\n",
      "Day 153: Bought 0.0 shares at 195.7100067138672, Cash left: 0\n",
      "Day 154: Bought 0.0 shares at 193.17999267578125, Cash left: 0\n",
      "Day 155: Bought 0.0 shares at 194.7100067138672, Cash left: 0\n",
      "Day 156: Bought 0.0 shares at 197.9600067138672, Cash left: 0\n",
      "Day 157: Bought 0.0 shares at 198.11000061035156, Cash left: 0\n",
      "Day 158: Bought 0.0 shares at 197.57000732421875, Cash left: 0\n",
      "Day 159: Bought 0.0 shares at 195.88999938964844, Cash left: 0\n",
      "Day 160: Bought 0.0 shares at 196.94000244140625, Cash left: 0\n",
      "Day 161: Bought 0.0 shares at 194.8300018310547, Cash left: 0\n",
      "Day 162: Sold 1 share at 194.67999267578125, Cash: 194.67999267578125\n",
      "Day 163: Sold 1 share at 193.6000061035156, Cash: 388.2799987792969\n",
      "Day 164: Sold 1 share at 193.0500030517578, Cash: 581.3300018310547\n",
      "Day 165: Sold 1 share at 193.1499938964844, Cash: 774.4799957275391\n",
      "Day 166: Sold 1 share at 193.5800018310547, Cash: 968.0599975585938\n",
      "Day 167: Sold 1 share at 192.52999877929688, Cash: 1160.5899963378906\n",
      "Day 168: Sold 1 share at 185.63999938964844, Cash: 1346.229995727539\n",
      "Day 169: Sold 1 share at 184.25, Cash: 1530.479995727539\n",
      "Day 170: Sold 1 share at 181.91000366210935, Cash: 1712.3899993896484\n",
      "Day 171: Sold 1 share at 181.17999267578125, Cash: 1893.5699920654297\n",
      "Day 173: Sold 1 share at 185.13999938964844, Cash: 2078.709991455078\n",
      "Day 174: Sold 1 share at 186.19000244140625, Cash: 2264.8999938964844\n",
      "Day 175: Sold 1 share at 185.58999633789065, Cash: 2450.489990234375\n",
      "Day 176: Sold 1 share at 185.9199981689453, Cash: 2636.4099884033203\n",
      "Day 177: Sold 1 share at 183.6300048828125, Cash: 2820.039993286133\n",
      "Day 178: Sold 1 share at 182.67999267578125, Cash: 3002.719985961914\n",
      "Day 180: Bought 1 share at 191.55999755859375, Cash left: 2811.1599884033203\n",
      "Day 181: Bought 1 share at 193.88999938964844, Cash left: 2617.269989013672\n",
      "Day 182: Bought 1 share at 195.17999267578125, Cash left: 2422.0899963378906\n",
      "Day 183: Bought 1 share at 194.5, Cash left: 2227.5899963378906\n",
      "Day 184: Bought 1 share at 194.1699981689453, Cash left: 2033.4199981689453\n",
      "Day 185: Bought 1 share at 192.4199981689453, Cash left: 1841.0\n",
      "Day 186: Bought 1 share at 191.72999572753903, Cash left: 1649.270004272461\n",
      "Day 187: Bought 1 share at 188.0399932861328, Cash left: 1461.2300109863281\n",
      "Day 188: Bought 1 share at 184.3999938964844, Cash left: 1276.8300170898438\n",
      "Day 189: Sold 1 share at 186.86000061035156, Cash: 1463.6900177001953\n",
      "Day 190: Sold 1 share at 185.8500061035156, Cash: 1649.540023803711\n",
      "Day 191: Sold 1 share at 187.67999267578125, Cash: 1837.2200164794922\n",
      "Day 192: Sold 1 share at 189.3000030517578, Cash: 2026.52001953125\n",
      "Day 193: Bought 1 share at 189.41000366210935, Cash left: 1837.1100158691406\n",
      "Day 194: Bought 1 share at 188.32000732421875, Cash left: 1648.7900085449219\n",
      "Day 195: Bought 1 share at 188.8500061035156, Cash left: 1459.9400024414062\n",
      "Day 196: Bought 1 share at 187.1499938964844, Cash left: 1272.7900085449219\n",
      "Day 197: Sold 1 share at 185.0399932861328, Cash: 1457.8300018310547\n",
      "Day 198: Sold 1 share at 184.1499938964844, Cash: 1641.979995727539\n",
      "Day 199: Sold 1 share at 183.86000061035156, Cash: 1825.8399963378906\n",
      "Day 200: Sold 1 share at 182.30999755859375, Cash: 2008.1499938964844\n",
      "Day 201: Sold 1 share at 181.55999755859375, Cash: 2189.709991455078\n",
      "Day 202: Sold 1 share at 182.32000732421875, Cash: 2372.029998779297\n",
      "Day 203: Sold 1 share at 184.3699951171875, Cash: 2556.3999938964844\n",
      "Day 204: Sold 1 share at 182.52000427246097, Cash: 2738.9199981689453\n",
      "Day 205: Sold 1 share at 181.16000366210935, Cash: 2920.0800018310547\n",
      "Day 206: Sold 1 share at 182.6300048828125, Cash: 3102.710006713867\n",
      "Day 207: Sold 1 share at 181.4199981689453, Cash: 3284.1300048828125\n",
      "Day 208: Sold 1 share at 180.75, Cash: 3464.8800048828125\n",
      "Day 209: Sold 1 share at 179.66000366210938, Cash: 3644.540008544922\n",
      "Day 210: Sold 1 share at 175.10000610351562, Cash: 3819.6400146484375\n",
      "Day 211: Sold 1 share at 170.1199951171875, Cash: 3989.760009765625\n",
      "Day 212: Sold 1 share at 169.1199951171875, Cash: 4158.8800048828125\n",
      "Day 213: Sold 1 share at 169.0, Cash: 4327.8800048828125\n",
      "Day 214: Sold 1 share at 170.72999572753906, Cash: 4498.610000610352\n",
      "Day 215: Sold 1 share at 172.75, Cash: 4671.360000610352\n",
      "Day 216: Sold 1 share at 173.22999572753906, Cash: 4844.589996337891\n",
      "Day 217: Sold 1 share at 171.1300048828125, Cash: 5015.720001220703\n",
      "Day 218: Bought 1 share at 173.0, Cash left: 4842.720001220703\n",
      "Day 219: Bought 1 share at 172.6199951171875, Cash left: 4670.100006103516\n",
      "Day 220: Bought 1 share at 173.72000122070312, Cash left: 4496.3800048828125\n",
      "Day 221: Bought 1 share at 176.0800018310547, Cash left: 4320.300003051758\n",
      "Day 222: Bought 1 share at 178.6699981689453, Cash left: 4141.6300048828125\n",
      "Day 223: Bought 1 share at 171.3699951171875, Cash left: 3970.260009765625\n",
      "Day 224: Bought 1 share at 172.27999877929688, Cash left: 3797.980010986328\n",
      "Day 225: Bought 1 share at 170.85000610351562, Cash left: 3627.1300048828125\n",
      "Day 226: Bought 1 share at 169.7100067138672, Cash left: 3457.4199981689453\n",
      "Day 228: Bought 1 share at 171.47999572753906, Cash left: 3285.9400024414062\n",
      "Day 229: Bought 1 share at 170.02999877929688, Cash left: 3115.9100036621094\n",
      "Day 230: Bought 1 share at 168.83999633789062, Cash left: 2947.0700073242188\n",
      "Day 231: Bought 1 share at 169.64999389648438, Cash left: 2777.4200134277344\n",
      "Day 232: Bought 1 share at 168.82000732421875, Cash left: 2608.6000061035156\n",
      "Day 233: Bought 1 share at 169.5800018310547, Cash left: 2439.020004272461\n",
      "Day 234: Bought 1 share at 168.4499969482422, Cash left: 2270.5700073242188\n",
      "Day 235: Bought 1 share at 169.6699981689453, Cash left: 2100.9000091552734\n",
      "Day 236: Bought 1 share at 167.77999877929688, Cash left: 1933.1200103759766\n",
      "Day 238: Bought 1 share at 176.5500030517578, Cash left: 1756.5700073242188\n",
      "Day 239: Bought 1 share at 172.69000244140625, Cash left: 1583.8800048828125\n",
      "Day 240: Bought 1 share at 169.3800048828125, Cash left: 1414.5\n",
      "Day 241: Bought 1 share at 168.0, Cash left: 1246.5\n",
      "Day 242: Bought 1 share at 167.0399932861328, Cash left: 1079.4600067138672\n",
      "Day 243: Bought 1 share at 165.0, Cash left: 914.4600067138672\n",
      "Day 244: Sold 1 share at 165.83999633789062, Cash: 1080.3000030517578\n",
      "Day 245: Bought 1 share at 166.89999389648438, Cash left: 913.4000091552734\n",
      "Day 246: Bought 1 share at 169.02000427246094, Cash left: 744.3800048828125\n",
      "Day 247: Bought 1 share at 169.88999938964844, Cash left: 574.4900054931641\n",
      "Day 248: Bought 1 share at 169.3000030517578, Cash left: 405.19000244140625\n",
      "Day 250: Bought 1 share at 170.3300018310547, Cash left: 234.86000061035156\n",
      "Day 251: Bought 1 share at 169.3000030517578, Cash left: 65.55999755859375\n",
      "Day 254: Bought 0.0 shares at 181.7100067138672, Cash left: 0\n",
      "Day 255: Bought 0.0 shares at 182.3999938964844, Cash left: 0\n",
      "Day 256: Bought 0.0 shares at 182.7400054931641, Cash left: 0\n",
      "Day 257: Bought 0.0 shares at 184.57000732421875, Cash left: 0\n",
      "Day 258: Bought 0.0 shares at 183.0500030517578, Cash left: 0\n",
      "Day 259: Bought 0.0 shares at 186.27999877929688, Cash left: 0\n",
      "Day 260: Bought 0.0 shares at 187.42999267578125, Cash left: 0\n",
      "Day 261: Bought 0.0 shares at 189.72000122070312, Cash left: 0\n",
      "Day 262: Bought 0.0 shares at 189.83999633789065, Cash left: 0\n",
      "Day 263: Bought 0.0 shares at 189.8699951171875, Cash left: 0\n",
      "Day 264: Bought 0.0 shares at 191.0399932861328, Cash left: 0\n",
      "Day 265: Bought 0.0 shares at 192.3500061035156, Cash left: 0\n",
      "Day 266: Bought 0.0 shares at 190.8999938964844, Cash left: 0\n",
      "Day 267: Bought 0.0 shares at 186.8800048828125, Cash left: 0\n",
      "Day 268: Bought 0.0 shares at 189.97999572753903, Cash left: 0\n",
      "Day 269: Bought 0.0 shares at 189.9900054931641, Cash left: 0\n",
      "Day 270: Bought 0.0 shares at 190.2899932861328, Cash left: 0\n",
      "Day 271: Bought 0.0 shares at 191.2899932861328, Cash left: 0\n",
      "Day 272: Bought 0.0 shares at 192.25, Cash left: 0\n",
      "Day 273: Bought 0.0 shares at 194.02999877929688, Cash left: 0\n",
      "Day 274: Bought 0.0 shares at 194.3500061035156, Cash left: 0\n",
      "Day 275: Bought 0.0 shares at 195.8699951171875, Cash left: 0\n",
      "Day 276: Bought 0.0 shares at 194.47999572753903, Cash left: 0\n",
      "Day 277: Bought 0.0 shares at 196.88999938964844, Cash left: 0\n",
      "Day 278: Bought 0.0 shares at 193.1199951171875, Cash left: 0\n",
      "Day 281: Bought 0.0 shares at 214.2400054931641, Cash left: 0\n",
      "Day 282: Bought 0.0 shares at 212.4900054931641, Cash left: 0\n",
      "Day 284: Bought 0.0 shares at 214.2899932861328, Cash left: 0\n",
      "Day 285: Bought 0.0 shares at 209.67999267578125, Cash left: 0\n",
      "Day 286: Bought 0.0 shares at 207.4900054931641, Cash left: 0\n",
      "Day 287: Bought 0.0 shares at 208.13999938964844, Cash left: 0\n",
      "Day 288: Sold 1 share at 209.07000732421875, Cash: 209.07000732421875\n",
      "Day 290: Bought 0.0 shares at 214.1000061035156, Cash left: 0\n",
      "Day 291: Sold 1 share at 210.6199951171875, Cash: 210.6199951171875\n",
      "Day 293: Bought 0.0 shares at 220.27000427246097, Cash left: 0\n",
      "Day 294: Bought 0.0 shares at 221.5500030517578, Cash left: 0\n",
      "Day 296: Bought 0.0 shares at 227.82000732421875, Cash left: 0\n",
      "Day 297: Bought 0.0 shares at 228.67999267578125, Cash left: 0\n",
      "Day 298: Bought 0.0 shares at 232.97999572753903, Cash left: 0\n",
      "Day 299: Bought 0.0 shares at 227.57000732421875, Cash left: 0\n",
      "Day 300: Bought 0.0 shares at 230.5399932861328, Cash left: 0\n",
      "Day 301: Bought 0.0 shares at 234.3999938964844, Cash left: 0\n",
      "Day 302: Bought 0.0 shares at 234.82000732421875, Cash left: 0\n",
      "Day 303: Bought 0.0 shares at 228.8800048828125, Cash left: 0\n",
      "Day 304: Bought 0.0 shares at 224.17999267578125, Cash left: 0\n",
      "Day 305: Sold 1 share at 224.30999755859375, Cash: 224.30999755859375\n",
      "Day 306: Sold 1 share at 223.9600067138672, Cash: 448.27000427246094\n",
      "Day 307: Sold 1 share at 225.0099945068359, Cash: 673.2799987792969\n",
      "Day 308: Sold 1 share at 218.5399932861328, Cash: 891.8199920654297\n",
      "Day 309: Sold 1 share at 217.4900054931641, Cash: 1109.3099975585938\n",
      "Day 310: Sold 1 share at 217.9600067138672, Cash: 1327.270004272461\n",
      "Day 311: Sold 1 share at 218.2400054931641, Cash: 1545.510009765625\n",
      "Day 312: Sold 1 share at 218.8000030517578, Cash: 1764.3100128173828\n",
      "Day 313: Sold 1 share at 222.0800018310547, Cash: 1986.3900146484375\n",
      "Day 314: Sold 1 share at 218.36000061035156, Cash: 2204.750015258789\n",
      "Day 315: Sold 1 share at 219.86000061035156, Cash: 2424.6100158691406\n",
      "Day 316: Sold 1 share at 209.27000427246097, Cash: 2633.8800201416016\n",
      "Day 317: Sold 1 share at 207.22999572753903, Cash: 2841.1100158691406\n",
      "Day 318: Sold 1 share at 209.82000732421875, Cash: 3050.9300231933594\n",
      "Day 319: Sold 1 share at 213.30999755859375, Cash: 3264.240020751953\n",
      "Day 320: Sold 1 share at 216.2400054931641, Cash: 3480.480026245117\n",
      "Day 321: Sold 1 share at 217.52999877929688, Cash: 3698.010025024414\n",
      "Day 322: Bought 1 share at 221.27000427246097, Cash left: 3476.740020751953\n",
      "Day 323: Bought 1 share at 221.72000122070312, Cash left: 3255.02001953125\n",
      "Day 324: Bought 1 share at 224.72000122070312, Cash left: 3030.300018310547\n",
      "Day 325: Bought 1 share at 226.0500030517578, Cash left: 2804.250015258789\n",
      "Day 326: Bought 1 share at 225.88999938964844, Cash left: 2578.3600158691406\n",
      "Day 327: Bought 1 share at 226.5099945068359, Cash left: 2351.8500213623047\n",
      "Day 328: Bought 1 share at 226.3999938964844, Cash left: 2125.4500274658203\n",
      "Day 329: Bought 1 share at 224.52999877929688, Cash left: 1900.9200286865234\n",
      "Day 330: Bought 1 share at 226.83999633789065, Cash left: 1674.0800323486328\n",
      "Day 331: Bought 1 share at 227.17999267578125, Cash left: 1446.9000396728516\n",
      "Day 332: Bought 1 share at 228.02999877929688, Cash left: 1218.8700408935547\n",
      "Day 333: Bought 1 share at 226.4900054931641, Cash left: 992.3800354003906\n",
      "Day 334: Bought 1 share at 229.7899932861328, Cash left: 762.5900421142578\n",
      "Day 335: Bought 1 share at 229.0, Cash left: 533.5900421142578\n",
      "Day 336: Bought 1 share at 222.77000427246097, Cash left: 310.8200378417969\n",
      "Day 337: Sold 1 share at 220.8500061035156, Cash: 531.6700439453125\n",
      "Day 338: Sold 1 share at 222.3800048828125, Cash: 754.050048828125\n",
      "Day 339: Sold 1 share at 220.82000732421875, Cash: 974.8700561523438\n",
      "Day 340: Sold 1 share at 220.91000366210935, Cash: 1195.7800598144531\n",
      "Day 341: Sold 1 share at 220.11000061035156, Cash: 1415.8900604248047\n",
      "Day 342: Sold 1 share at 222.66000366210935, Cash: 1638.550064086914\n",
      "Day 343: Sold 1 share at 222.77000427246097, Cash: 1861.320068359375\n",
      "Day 344: Sold 1 share at 222.5, Cash: 2083.820068359375\n",
      "Day 345: Sold 1 share at 216.32000732421875, Cash: 2300.1400756835938\n",
      "Day 346: Sold 1 share at 216.7899932861328, Cash: 2516.9300689697266\n",
      "Day 347: Sold 1 share at 220.69000244140625, Cash: 2737.620071411133\n",
      "Day 349: Bought 1 share at 228.1999969482422, Cash left: 2509.4200744628906\n",
      "Day 350: Bought 1 share at 226.47000122070312, Cash left: 2282.9500732421875\n",
      "Day 351: Bought 1 share at 227.3699951171875, Cash left: 2055.580078125\n",
      "Day 352: Bought 1 share at 226.3699951171875, Cash left: 1829.2100830078125\n",
      "Day 353: Bought 1 share at 227.52000427246097, Cash left: 1601.6900787353516\n",
      "Day 354: Bought 1 share at 227.7899932861328, Cash left: 1373.9000854492188\n",
      "Day 356: Bought 1 share at 226.2100067138672, Cash left: 1147.6900787353516\n",
      "Day 357: Bought 1 share at 226.77999877929688, Cash left: 920.9100799560547\n",
      "Day 358: Bought 1 share at 225.6699981689453, Cash left: 695.2400817871094\n",
      "Day 359: Bought 1 share at 226.8000030517578, Cash left: 468.44007873535156\n",
      "Day 360: Sold 1 share at 221.69000244140625, Cash: 690.1300811767578\n",
      "Day 361: Sold 1 share at 225.77000427246097, Cash: 915.9000854492188\n",
      "Day 362: Bought 1 share at 229.5399932861328, Cash left: 686.3600921630859\n",
      "Day 363: Bought 1 share at 229.0399932861328, Cash left: 457.3200988769531\n",
      "Day 364: Bought 1 share at 230.38999938964844, Cash left: 226.9300994873047\n",
      "Total cash invested: 10000\n",
      "Stock AAPL\n",
      "Final Portfolio Value: 12560.381412437266\n",
      "Cash: 226.9300994873047, Shares held: 53.53292827650448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    Stock Name  Day Action         Cash Shares Held  Portfolio Value  \\\n",
       " 0         AAPL    0    Buy  9831.460007           1     10000.000000   \n",
       " 1         AAPL    1    Buy  9664.010010           2      9998.910004   \n",
       " 2         AAPL    2    Buy  9498.220016           3      9995.589996   \n",
       " 3         AAPL    3   Hold  9498.220016           3     10018.930038   \n",
       " 4         AAPL    4    Buy  9324.720016           4     10018.720016   \n",
       " ..         ...  ...    ...          ...         ...              ...   \n",
       " 360       AAPL  360   Sell   690.130081   51.532928     12114.465077   \n",
       " 361       AAPL  361   Sell   915.900085   50.532928     12324.719518   \n",
       " 362       AAPL  362    Buy   686.360092   51.532928     12515.228103   \n",
       " 363       AAPL  363    Buy   457.320099   52.532928     12489.461639   \n",
       " 364       AAPL  364    Buy   226.930099   53.532928     12560.381412   \n",
       " \n",
       "      Stock Price       Date  \n",
       " 0     168.539993 2023-05-02  \n",
       " 1     167.449997 2023-05-03  \n",
       " 2     165.789993 2023-05-04  \n",
       " 3     173.570007 2023-05-05  \n",
       " 4     173.500000 2023-05-08  \n",
       " ..           ...        ...  \n",
       " 360   221.690002 2024-10-07  \n",
       " 361   225.770004 2024-10-08  \n",
       " 362   229.539993 2024-10-09  \n",
       " 363   229.039993 2024-10-10  \n",
       " 364   230.389999 2024-10-14  \n",
       " \n",
       " [365 rows x 8 columns],\n",
       " 226.9300994873047)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_market_simulation(model, 10000, 365, get_stock_data('AAPL').tail(365), print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
