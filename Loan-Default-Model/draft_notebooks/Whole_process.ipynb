{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest loan amount that in default is 35000 and that person makes 115000 annually\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import pandasql as psql\n",
    "\n",
    "data = pd.read_csv('credit_risk_dataset.csv').dropna()\n",
    "chartable = data.head(5000)\n",
    "not_paid = chartable[chartable['loan_status'] == 0]\n",
    "data.head(5)\n",
    "largest_unpaid = not_paid[\"loan_amnt\"].idxmax()\n",
    "print(f'The largest loan amount that in default is {not_paid.loc[largest_unpaid, \"loan_amnt\"]} and that person makes {chartable.loc[largest_unpaid, \"person_income\"]} annually')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced area chart for loan amount vs person income\n",
    "area_loan_amnt = alt.Chart(chartable).mark_area().encode(\n",
    "    alt.X('loan_amnt', title='Loan Amount', scale=alt.Scale(domain=(0, 35000))),  # Adjusted domain to match typical loan amounts\n",
    "    alt.Y('person_income', title='Annual Income', scale=alt.Scale(domain=(0, 350000))),  # Added scale for y-axis\n",
    "    color=alt.Color('loan_status', title='Loan Status'),\n",
    "    tooltip=['loan_amnt', 'person_income', 'loan_status']\n",
    ").properties(\n",
    "    width=800,\n",
    "    title='Loan Amount vs Person Income'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "chartable = pd.read_csv('credit_risk_dataset.csv').dropna()\n",
    "chartable['loan_status_mapped'] = chartable['loan_status'].map({1: '1: Default', 0: '0: Fully Paid'})\n",
    "chartable['person_age'] = chartable[chartable['person_age'] <= 100]['person_age']\n",
    "\n",
    "\n",
    "# Existing histograms\n",
    "hist_age = alt.Chart(chartable).mark_bar().encode(\n",
    "    alt.X('person_age:Q', bin=alt.Bin(maxbins=30), title='Person Age'),\n",
    "    alt.Y('count()', title='Count'),\n",
    "    color='loan_status_mapped:O',\n",
    "    tooltip=['count()', 'person_age','loan_status_mapped:O',]\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300,\n",
    "    title='Distribution of Person Age'\n",
    ")\n",
    "\n",
    "hist_income = alt.Chart(chartable).mark_bar().encode(\n",
    "    alt.X('loan_percent_income:Q', bin=alt.Bin(maxbins=30), title='Loan % Income Income'),\n",
    "    alt.Y('count()', title='Count'),\n",
    "    color='loan_status_mapped:O',\n",
    "    tooltip=['count()', 'loan_percent_income','loan_status_mapped']\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300,\n",
    "    title='Distribution of Loan & Income Ratio'\n",
    ")\n",
    "\n",
    "hist_loan_amnt = alt.Chart(chartable).mark_bar().encode(\n",
    "    alt.X('loan_amnt:Q', bin=alt.Bin(maxbins=30), title='Loan Amount'),\n",
    "    alt.Y('count()', title='Count'),\n",
    "    color='loan_status_mapped:O',\n",
    "    tooltip=['count()', 'loan_amnt','loan_status_mapped']\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300,\n",
    "    title='Distribution of Loan Amount'\n",
    ")\n",
    "\n",
    "hist_loan_int_rate = alt.Chart(chartable).mark_bar().encode(\n",
    "    alt.X('loan_int_rate:Q', bin=alt.Bin(maxbins=30), title='Loan Interest Rate'),\n",
    "    alt.Y('count()', title='Count'),\n",
    "    color='loan_status_mapped:O',\n",
    "    tooltip=['count()', 'loan_int_rate','loan_status_mapped']\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300,\n",
    "    title='Distribution of Loan Interest Rate'\n",
    ")\n",
    "\n",
    "hist_loan_grade = alt.Chart(chartable).mark_bar().encode(\n",
    "    alt.X('loan_grade', title='Loan Grade'),\n",
    "    alt.Y('count()', title='Count'),\n",
    "    color='loan_status_mapped:O',\n",
    "    tooltip=['count()', 'loan_grade','loan_status_mapped']\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300,\n",
    "    title='Distribution of Loan Grade'\n",
    ")\n",
    "\n",
    "hist_loan_intent = alt.Chart(chartable).mark_bar().encode(\n",
    "    alt.X('loan_intent', title='Loan Intent'),\n",
    "    alt.Y('count()', title='Count'),\n",
    "    color='loan_status_mapped:O',\n",
    "    tooltip=['count()', 'loan_intent','loan_status_mapped']\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300,\n",
    "    title='Distribution of Loan Intent'\n",
    ")\n",
    "\n",
    "# Concatenate the histograms and the area chart in a grid layout\n",
    "combined_charts = alt.vconcat(\n",
    "    alt.hconcat(hist_age, hist_income, hist_loan_intent),\n",
    "    alt.hconcat(hist_loan_amnt, hist_loan_int_rate, hist_loan_grade),\n",
    ")\n",
    "\n",
    "combined_charts.save('Property_Distribution.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_intent_EDUCATION</th>\n",
       "      <th>loan_intent_HOMEIMPROVEMENT</th>\n",
       "      <th>loan_intent_MEDICAL</th>\n",
       "      <th>loan_intent_PERSONAL</th>\n",
       "      <th>loan_intent_VENTURE</th>\n",
       "      <th>DTI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.907594</td>\n",
       "      <td>-0.122674</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.453433</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.003984</td>\n",
       "      <td>0.901434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.952527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.691791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.969132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.066064</td>\n",
       "      <td>-0.914907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050866</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.367627</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.653141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.939413</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.615762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.432183</td>\n",
       "      <td>-0.914907</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.911932</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.656678</td>\n",
       "      <td>0.336918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.764540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.691791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.778785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.749123</td>\n",
       "      <td>-0.018433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.189833</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.003984</td>\n",
       "      <td>0.759857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.388567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.939413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.417232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.590653</td>\n",
       "      <td>-0.196445</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.772966</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.003984</td>\n",
       "      <td>0.587814</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.576554</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.444169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.439403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age  person_income  person_home_ownership  person_emp_length  \\\n",
       "0   -0.907594      -0.122674                    2.0          28.453433   \n",
       "1   -1.066064      -0.914907                    0.0           0.050866   \n",
       "2   -0.432183      -0.914907                    1.0          -0.911932   \n",
       "3   -0.749123      -0.018433                    2.0          -0.189833   \n",
       "4   -0.590653      -0.196445                    2.0           0.772966   \n",
       "\n",
       "   loan_grade  loan_amnt  loan_int_rate  loan_status  loan_percent_income  \\\n",
       "0         3.0   4.003984       0.901434          1.0             3.952527   \n",
       "1         1.0  -1.367627       0.026882          0.0            -0.653141   \n",
       "2         2.0  -0.656678       0.336918          1.0             3.764540   \n",
       "3         2.0   4.003984       0.759857          1.0             3.388567   \n",
       "4         2.0   4.003984       0.587814          1.0             3.576554   \n",
       "\n",
       "   cb_person_default_on_file  cb_person_cred_hist_length  \\\n",
       "0                        1.0                   -0.691791   \n",
       "1                        0.0                   -0.939413   \n",
       "2                        0.0                   -0.691791   \n",
       "3                        0.0                   -0.939413   \n",
       "4                        1.0                   -0.444169   \n",
       "\n",
       "   loan_intent_EDUCATION  loan_intent_HOMEIMPROVEMENT  loan_intent_MEDICAL  \\\n",
       "0                    0.0                          0.0                  0.0   \n",
       "1                    1.0                          0.0                  0.0   \n",
       "2                    0.0                          0.0                  1.0   \n",
       "3                    0.0                          0.0                  1.0   \n",
       "4                    0.0                          0.0                  1.0   \n",
       "\n",
       "   loan_intent_PERSONAL  loan_intent_VENTURE       DTI  \n",
       "0                   1.0                  0.0  3.969132  \n",
       "1                   0.0                  0.0 -0.615762  \n",
       "2                   0.0                  0.0  3.778785  \n",
       "3                   0.0                  0.0  3.417232  \n",
       "4                   0.0                  0.0  4.439403  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OrdinalEncoder\n",
    "\n",
    "# def preprocess(data = data):\n",
    "loan_grade_order = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "home_ownership_order = ['OWN', 'MORTGAGE', 'RENT', 'OTHER']\n",
    "\n",
    "loan_grade_encoder = OrdinalEncoder(categories=[loan_grade_order], dtype=int)\n",
    "home_ownership_encoder = OrdinalEncoder(categories=[home_ownership_order], dtype=int)\n",
    "\n",
    "data['loan_grade'] = loan_grade_encoder.fit_transform(data.loan_grade.values.reshape(-1,1))\n",
    "data['person_home_ownership'] = home_ownership_encoder.fit_transform(data.person_home_ownership.values.reshape(-1,1))\n",
    "data = pd.get_dummies(data, columns=['loan_intent'], drop_first=True)\n",
    "data['cb_person_default_on_file'] = data['cb_person_default_on_file'].map({'Y': 1, 'N': 0})\n",
    "data['DTI'] = data['loan_amnt'] / data['person_income']\n",
    "data = data.astype(float)\n",
    "\n",
    "numeric_features = ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_percent_income', 'cb_person_cred_hist_length', 'DTI']\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "data[numeric_features] = standard_scaler.fit_transform(data[numeric_features])\n",
    "data['loan_int_rate'] = robust_scaler.fit_transform(data['loan_int_rate'].values.reshape(-1,1))\n",
    "\n",
    "# return data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n",
    "    return [conf_matrix, class_report]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[4248  195]\n",
      " [ 616  669]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.96      0.91      4443\n",
      "         1.0       0.77      0.52      0.62      1285\n",
      "\n",
      "    accuracy                           0.86      5728\n",
      "   macro avg       0.82      0.74      0.77      5728\n",
      "weighted avg       0.85      0.86      0.85      5728\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[4248,  195],\n",
       "        [ 616,  669]]),\n",
       " '              precision    recall  f1-score   support\\n\\n         0.0       0.87      0.96      0.91      4443\\n         1.0       0.77      0.52      0.62      1285\\n\\n    accuracy                           0.86      5728\\n   macro avg       0.82      0.74      0.77      5728\\nweighted avg       0.85      0.86      0.85      5728\\n']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "X = data.drop('loan_status', axis=1)\n",
    "y = data['loan_status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "evaluate_model(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.96      0.91      4443\n",
      "         1.0       0.77      0.52      0.62      1285\n",
      "\n",
      "    accuracy                           0.86      5728\n",
      "   macro avg       0.82      0.74      0.77      5728\n",
      "weighted avg       0.85      0.86      0.85      5728\n",
      "\n",
      "\n",
      "\n",
      "Model: Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.93      0.93      4443\n",
      "         1.0       0.77      0.78      0.77      1285\n",
      "\n",
      "    accuracy                           0.90      5728\n",
      "   macro avg       0.85      0.85      0.85      5728\n",
      "weighted avg       0.90      0.90      0.90      5728\n",
      "\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96      4443\n",
      "         1.0       0.97      0.73      0.83      1285\n",
      "\n",
      "    accuracy                           0.93      5728\n",
      "   macro avg       0.95      0.86      0.90      5728\n",
      "weighted avg       0.94      0.93      0.93      5728\n",
      "\n",
      "\n",
      "\n",
      "Model: Gradient Boosting\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.95      4443\n",
      "         1.0       0.94      0.71      0.81      1285\n",
      "\n",
      "    accuracy                           0.92      5728\n",
      "   macro avg       0.93      0.85      0.88      5728\n",
      "weighted avg       0.92      0.92      0.92      5728\n",
      "\n",
      "\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94      4443\n",
      "         1.0       0.91      0.63      0.74      1285\n",
      "\n",
      "    accuracy                           0.90      5728\n",
      "   macro avg       0.91      0.81      0.84      5728\n",
      "weighted avg       0.90      0.90      0.90      5728\n",
      "\n",
      "\n",
      "\n",
      "Model: K-Nearest Neighbors\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.97      0.93      4443\n",
      "         1.0       0.85      0.63      0.72      1285\n",
      "\n",
      "    accuracy                           0.89      5728\n",
      "   macro avg       0.87      0.80      0.83      5728\n",
      "weighted avg       0.89      0.89      0.89      5728\n",
      "\n",
      "\n",
      "\n",
      "Model: Neural Network\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.97      0.94      4443\n",
      "         1.0       0.87      0.67      0.75      1285\n",
      "\n",
      "    accuracy                           0.90      5728\n",
      "   macro avg       0.89      0.82      0.85      5728\n",
      "weighted avg       0.90      0.90      0.90      5728\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardobenjamin/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# List of models to test\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Neural Network': MLPClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m conf_matrix_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(matrix, \n\u001b[1;32m      2\u001b[0m                             columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Negative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Positive\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      3\u001b[0m                             index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual Negative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual Positive\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Melt the DataFrame to long format\u001b[39;00m\n\u001b[1;32m      6\u001b[0m conf_matrix_melted \u001b[38;5;241m=\u001b[39m conf_matrix_df\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mmelt(id_vars\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matrix' is not defined"
     ]
    }
   ],
   "source": [
    "conf_matrix_df = pd.DataFrame(matrix, \n",
    "                            columns=['Predicted Negative', 'Predicted Positive'], \n",
    "                            index=['Actual Negative', 'Actual Positive'])\n",
    "\n",
    "# Melt the DataFrame to long format\n",
    "conf_matrix_melted = conf_matrix_df.reset_index().melt(id_vars='index')\n",
    "conf_matrix_melted.columns = ['Actual', 'Predicted', 'Count']\n",
    "\n",
    "# Create the heatmap using Altair\n",
    "heatmap = alt.Chart(conf_matrix_melted).mark_rect().encode(\n",
    "    x='Predicted:O',\n",
    "    y='Actual:O',\n",
    "    color='Count:Q',\n",
    "    tooltip=['Actual', 'Predicted', 'Count']\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300,\n",
    "    title='Confusion Matrix'\n",
    ")\n",
    "\n",
    "# Add text annotations\n",
    "text = heatmap.mark_text(baseline='middle').encode(\n",
    "    text='Count:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.Count > conf_matrix_melted['Count'].mean(), \n",
    "        alt.value('black'), \n",
    "        alt.value('white')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Combine heatmap and text\n",
    "conf_matrix_chart = heatmap + text\n",
    "\n",
    "# Display the chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLPClassifier' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[1;32m      2\u001b[0m features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m      3\u001b[0m importance_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m: features, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_importance})\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "feature_importance = model.feature_importances_\n",
    "features = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Create the bar chart\n",
    "bar_chart = alt.Chart(importance_df.head(10)).mark_bar().encode(\n",
    "    x=alt.X('Importance:Q', title='Importance'),\n",
    "    y=alt.Y('Feature:O', sort='-x', title='Feature'),\n",
    "    tooltip=['Feature', 'Importance'],\n",
    "    color=alt.Color('Importance:Q', scale=alt.Scale(scheme='viridis'))\n",
    ").properties(\n",
    "    width=800,\n",
    "    title='Top 10 Feature Importance'\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[4366   77]\n",
      " [ 379  906]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.98      0.95      4443\n",
      "         1.0       0.92      0.71      0.80      1285\n",
      "\n",
      "    accuracy                           0.92      5728\n",
      "   macro avg       0.92      0.84      0.87      5728\n",
      "weighted avg       0.92      0.92      0.92      5728\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduardobenjamin/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_feature_importance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28meval\u001b[39m \u001b[38;5;241m=\u001b[39m evaluate_model(y_test, y_pred)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28meval\u001b[39m\n\u001b[0;32m----> 9\u001b[0m plot_feature_importance(model, X)\u001b[38;5;241m.\u001b[39mdisplay()\n\u001b[1;32m     10\u001b[0m plot_confusion_matrix(\u001b[38;5;28meval\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_feature_importance' is not defined"
     ]
    }
   ],
   "source": [
    "X = data.drop('loan_status', axis=1)\n",
    "y = data['loan_status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "eval = evaluate_model(y_test, y_pred)\n",
    "eval\n",
    "plot_feature_importance(model, X).display()\n",
    "plot_confusion_matrix(eval[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb.plot_importance(model, figsize=(12, 25), max_num_features=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
